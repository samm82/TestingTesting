Despite the prevalence and importance of software testing, it lacks
a standardized and consistent taxonomy, instead relying on a large body of
literature with many flaws---even within individual documents! This hinders
precise communication, contributing to misunderstandings when planning and
performing testing. In this \docType{}, we %systematically
explore the current state of software testing terminology by:
\begin{enumerate}
    \item identifying established standards and prominent testing resources,
    \item capturing relevant testing terms from these sources, along with their
          definitions and relationships (both explicit and implicit), and
    \item constructing visualizations to analyze these data.
\end{enumerate}
This process uncovers \approachCount{} test approaches and
\ifnotpaper four in-scope methods for deriving test approaches, such as those
    related to \fi \qualityCount{} software qualities\ifnotpaper\else\ that may
    imply additional related test approaches\fi. We also build
a tool for visualizing relations between test approaches and track flaws
both by detecting them automatically using this tool and by manually recording
them throughout our research process. This reveals \flawCount{} flaws,
including \multiSynCount{} terms used as synonyms to two (or more) disjoint
test approaches and \parSynCount{} pairs of test approaches that may either be
synonyms or have a parent-child relationship. This also highlights notable
confusion surrounding functional testing, \ifnotpaper operational acceptance
    testing, \fi recovery resting, and scalability testing. Our
findings make clear the urgent need for improved testing terminology so that
the discussion, analysis and implementation of various test approaches can be
more coherent. We provide some preliminary advice on how to achieve this
standardization.