\chapter{Detailed Scope Analysis}\label{app-scope}

As outlined in \Cref{scope-overview}, the scope of our research is limited to
testing applied to code itself. Throughout our research, we identify many
approaches that are out of scope based on this criteria.

\section{Hardware Testing}\label{hard-test}
While testing the software run \emph{on} or in control \emph{of} hardware is in
scope, testing performed on the hardware \emph{itself} is out of scope. The
following are some examples of hardware testing approaches we exclude from our
research:

\begin{itemize}
    \item Ergonomics testing and proximity-based testing \citepISTQB{}
          are out of scope, since they are used for testing hardware.
    \item \acf{emsec} testing \ifnotpaper
              (\citealp{ISO2021}; \citealp[p.~95]{ZhouEtAl2012})\else
              \cite{ISO2021}, \cite[p.~95]{ZhouEtAl2012}\fi, which deals with
          the ``security risk'' of ``information leakage via electromagnetic
          emanation'' \citep[p.~95]{ZhouEtAl2012}, is also out of scope.
          \ifnotpaper
    \item All the examples of domain-specific testing given by
          \citet[p.~26]{Firesmith2015} are focused on hardware, so these
          examples are out of scope. However, this might not be representative
          of \emph{all} kinds of domain-specific testing (e.g., \acf{ml} model
          testing seems domain-specific), so some subset of this approach may
          be in scope.
    \item Similarly, the examples of environmental tolerance testing given by
          \citet[p.~56]{Firesmith2015} do not seem to apply to software.
          For example, radiation tolerance testing seems to focus on hardware,
          such as motors \citep{MukhinEtAl2022}, robots \citep{ZhangEtAl2020},
          or ``nanolayered carbide and nitride materials''
          \citep[p.~1]{TunesEtAl2022}. Acceleration tolerance testing seems to
          focus on \accelTolTest{} and acoustic tolerance testing on rats
          \citep{HolleyEtAl1996}, which are even less related! Since these all
          focus on environment-specific factors that would not impact the code,
          these examples are out of scope. As with domain-specific testing, a
          subset of environmental tolerance testing may be in scope, but since
          no candidates have been found, this approach is out of scope for now.
    \item \citet{SPICE2022} uses the terms ``software
          qualification testing'' and ``system qualification testing'' in the
          context of the automotive industry. While these may be in scope, the
          more general idea of ``qualification testing'' seems to refer to the
          process of making a hardware component, such as an electronic
          component \citep{AhsanEtAl2020}, gas generator \citep{ParateEtAl2021}
          or photovoltaic device, ``into a reliable and marketable product''
          \citep[p.~1]{SuhirEtAl2013}. Therefore, it is currently unclear if
          this is in scope\todo{Investigate further}.
          \fi
    \item \acf{orthat} can be used when testing software \citep{Mandl1985} (in
          scope) but can also be used when testing hardware
          \citep[pp.~471--472]{Valcheva2013}, such as ``processors \dots{} made
          from pre-built and pre-tested hardware components'' \citetext{p.~471}
          (out of scope). A subset of \acs{orthat} called ``\acf{toat}'' is
          used for ``experimental design problems in manufacturing''
          \citep[p.~1573]{YuEtAl2011} or ``product and manufacturing process
          design'' \citep[p.~44]{Tsui2007} and is thus also out of scope.
          \ifnotpaper
    \item Since control systems often have a software \emph{and} hardware
          component \citep{ISO2015,PreußeEtAl2012,ForsythEtAl2004},
          only the software component is in scope. In some cases, it is
          unclear whether the ``loops''\footnote{Humorously, the testing of
              loops in chemical systems \citep{Dominguez-PumarEtAl2020} and
              copper loops \citep{Goralski1999} are out of scope.} being
          tested are implemented by software or hardware, such as those in
          wide-area damping controllers \citep{PierreEtAl2017,TrudnowskiEtAl2017}.
          \begin{itemize}
              \item A related note: ``path coverage'' or ``path testing''
                    seems to be able to refer to either paths through code
                    (as a subset of control-flow testing)
                    \citep[p.~5-13]{SWEBOK2024} or through a model, such as
                    a finite-state machine (as a subset of model-based
                    testing) \citep[p.~184]{DoğanEtAl2014}.
          \end{itemize}
    \item \phantomsection{}\label{phys-req-test}
          Physical testing (inferred from physical requirements
          \citep[p.~322]{IEEE2017} and requirements-based testing;
          see \Cref{req-apps}) tests ``a physical characteristic that a
          system or system component must possess'' \citetext{p.~322}.
          \fi
\end{itemize}

\section[V\&V of Other Artifacts]{\acs{vnv} of Other Artifacts}\label{other-vnv}
While many artifacts produced by the software life cycle can be tested, only
testing performed on the code \emph{itself} is in scope. Therefore, we exclude
the following test approaches either in full or in part:

\begin{itemize}
    \item Design reviews and documentation reviews are out of scope, as they
          focus on the \acs{vnv} of design \citep[pp.~132]{IEEE2017} and
          documentation \ifnotpaper \citetext{p.~144}\else
              \cite[pp.~144]{IEEE2017}\fi, respectively.
          \ifnotpaper
    \item Security audits can focus on ``an organization's \dots{} processes
          and infrastructure'' \citepISTQB{} (out of scope) or
          ``aim to ensure that all of the products installed on a site are
          secure when checked against the known vulnerabilities for those
          products'' \citep[p.~28]{Gerrard2000b} (in scope).
          \fi
    \item Error seeding is the ``process of intentionally adding
          known faults\footnote{
          \label{add-fault}While error seeding and fault injection testing
          both introduce faults as part of testing, they do so with different
          goals: to ``estimat[e] the number of faults remaining''
          \citep[p.~165]{IEEE2017} and ``test the robustness of the system''
          \citeyearpar[p.~42]{IEEE2022}, respectively. Therefore, these
          approaches are not considered synonyms, and the lack of this relation
          in the literature is not included in \Cref{syns} as a synonym
          flaw.} to those already in a computer program'',
          done to both ``monitor[] the rate of detection and removal'',
          which is a part of \acs{vnv} of the \acs{vnv} itself (out of scope),
          ``and estimat[e] the number of faults remaining''
          \citep[p.~165]{IEEE2017}, which helps verify the actual code (in scope).
    \item Fault injection testing, where ``faults are artificially
          introduced\textsuperscript{\ref{add-fault}} into the \acs{sut}
          [System Under Test]'', can be used to evaluate the effectiveness of a
          test suite \citep[p.~5-18]{SWEBOK2024}, which is a part of \acs{vnv}
          of the \acs{vnv} itself (out of scope), or ``to test
          the robustness of the system in the event of internal and
          external failures'' \citep[p.~42]{IEEE2022}, which helps verify
          the actual code (in scope).
    \item ``Mutation [t]esting was originally conceived as a
          technique to evaluate test suites in which a mutant is a slightly
          modified version of the \acs{sut}'' \citep[p.~5-15]{SWEBOK2024},
          which is in the realm of \acs{vnv} of the \acs{vnv} itself (out of
          scope). However, it ``can also be categorized as a structure-based
          technique'' and can be used to assist fuzz and metamorphic testing
          \citep[p.~5-15]{SWEBOK2024} (in scope).
          \ifnotpaper
    \item \phantomsection{}\label{nontech-req-test}
          Nontechnical testing (inferred from nontechnical requirements
          \citep[p.~293]{IEEE2017} and requirements-based testing; see
          \Cref{req-apps}) tests ``product and service acquisition or
          development that is not a property of the product or service''
          \citep[p.~293]{IEEE2017}.
          \fi
\end{itemize}

\section{Static Testing}\label{static-test}
Throughout the literature, static testing is more ambiguous than dynamic
testing, with more ad hoc processes and inconsistent in/exclusion from the
scope of software testing in general (see \flawref{static-test-flaw}).
Furthermore, it seems less relevant to our
original goal (the automatic generation of tests). In particular, many
techniques require human intervention, either by design (such as code
inspections) or to identify and resolve false positives (such as
intentional exceptions to linting rules). Nevertheless, understanding
the breadth of testing approaches requires a ``complete'' picture of how
software can be tested and how the various approaches relate to one another.
Parts of these static approaches may even be generated in the
future! For these reasons, we keep static testing in scope for this stage
of our work, even though static testing will likely be removed at a later
stage of analysis\thesisissueref{41,44} based on our original motivation.

% \ifnotpaper

% TODO: can this be formalized at all and included in a glossary or section?
% \citeauthor{Patton2006} introduces ``specification testing''
% \citeyearpar[pp.~56-62]{Patton2006}, which is static black-box testing.
% Most of this section is irrelevant to generating test cases, due to
% requiring human involvement and verifying the specification, not the code.
% However, it provides a ``Specification Terminology Checklist''
% \citep[p.~61]{Patton2006} that includes some keywords that, if found, could
% trigger an applicable warning to the user (similar to the idea behind the
% correctness/consistency checks project), indicating that a requirement is
% ambiguous or incomplete \citep[see][p.~1-8]{SWEBOK2024}:

% \begin{itemize}
%     \item \textbf{Potentially unrealistic:} always, every, all, none, every,
%           certainly, therefore, clearly, obviously, evidently
%     \item \textbf{Potentially vague:} some, sometimes, often, usually,
%           ordinarily, customarily, most, mostly, good, high-quality, fast,
%           quickly, cheap, inexpensive, efficient, small, stable
%     \item \textbf{Potentially incomplete:} etc., and so forth, and so on,
%           such as, handled, processed, rejected, skipped, eliminated,
%           if \dots{} then \dots{} (without ``else'' or ``otherwise''),
%           to be determined \citep[p.~408]{vanVliet2000}
% \end{itemize}

% \citeauthor{Patton2006} also provides a ``Generic Code Review Checklist''
% \citeyearpar[pp.~99-103]{Patton2006} in the context of static testing.
% Some of the following issues \emph{may} be able to be detected
% automatically (e.g., by linters), but this checklist is primarily used
% by human reviewers:

% \begin{itemize}
%     \item \phantomsection
%           \label{data-ref-errors}
%           Data reference errors: ``bugs caused by using a variable,
%           constant, \dots{} [etc.] that hasn't been properly declared
%           or initialized'' for its context \citetext{p.~99}
%     \item Data declaration errors: bugs ``caused by improperly
%           declaring or using variables or constants'' \citetext{p.~100}
%     \item Computation errors: ``essentially bad math''; e.g., type
%           mismatches, over/underflow, zero division, out of meaningful
%           range \citetext{p.~101}
%           \label{comp-errors}
%     \item Comparison errors: ``very susceptible to boundary condition
%           problems''; e.g., correct inclusion, floating point
%           comparisons \citetext{p.~101}
%     \item Control flow errors: bugs caused by ``loops and other control
%           constructs in the language not behaving as expected''
%           \citetext{p.~102}
%     \item Subroutine parameter errors: bugs ``due to incorrect passing
%           of data to and from software subroutines'' \citetext{p.~102}
%           (could also be called ``interface errors''
%           \citep[p.~416]{vanVliet2000})
%     \item Input/output errors: e.g., how are errors handled?
%           \citetext{pp.~102-103}
%     \item ASCII character handling, portability, compilation warnings
%           \citetext{p.~103}
% \end{itemize}

\section{Vague Terminology}\label{vague-terms}

Some terms are so vague that they do not provide any new, meaningful
information. For example, the ``systematic determination of the extent to
which an entity meets its specified criteria'' \citep[p.~167]{IEEE2017} is
certainly relevant to testing software; while this definition of
``evaluation'' may be meaningful when defining software testing generally,
it does not define a new approach or procedure and applies much more
broadly than just to testing. We decided\thesisissueref{39,44,28} that the
following terms are too vague to merit tracking in our glossaries or
analyzing further:
\begin{itemize}
    \item \textbf{Evaluation:} the ``systematic determination of the extent
          to which an entity meets its specified criteria''
          \citep[p.~167]{IEEE2017}
    \item \textbf{Product Analysis:} the ``process of evaluating a product by
          manual or automated means to determine if the product has certain
          characteristics'' \citep[p.~343]{IEEE2017}
    \item \textbf{Quality Audit:} ``a structured, independent process to
          determine if project activities comply with organizational and
          project policies, processes, and procedures'' \citep[p.~361]{IEEE2017}
          \todo{OG PMBOK}
    \item \textbf{Software Product Evaluation:} a ``technical operation that
          consists of producing an assessment of one or more characteristics
          of a software product according to a specified procedure''
          \citep[p.~424]{IEEE2017}
\end{itemize}

\section{Language-specific Approaches}\label{lang-test}
Specific programming languages are sometimes used to define test approaches.
If the reliance on a specific programming language is intentional, then
this really implies an underlying test approach that may be generalized to
other languages. These are therefore considered out-of-scope\thesisissueref{63},
including the following examples:

\begin{itemize}
    \item ``An approach \dots{} for JavaScript testing
          (referred to as Randomized)'' \citep[p.~192]{DoğanEtAl2014} is
          really just random testing used within JavaScript.
    \item ``SQL statement coverage'' \citep[Tab.~13]{DoğanEtAl2014}%
          \todo{OG Alalfi et al., 2010} is really just statement coverage
          used specifically for SQL statements.
    \item Testing for ``faults specific to PHP'' is just a subcategory of
          fault-based testing, since ``execution failures \dots{} caused by
          missing an included file, wrong MySQL quer[ies] and uncaught
          exceptions'' \citep[Tab.~27]{DoğanEtAl2014}\todo{OG Artzi et al., 2008}
          are not exclusive to PHP.
    \item While ``HTML testing'' is listed or implied by
          \citeauthor{Gerrard2000a} (\citeyear[Tab.~2]{Gerrard2000a};
          \citeyear[Tab.~1, p.~3]{Gerrard2000b}) and
          \citet[p.~220]{Patton2006}, it seems to be a combination of syntax
          testing, functionality testing, hyperlink testing/link checking,
          cross-browser compatibility testing, performance testing,
          content checking \citep[p.~3]{Gerrard2000b}, and grey-box testing
          \citep[pp.~218\==220]{Patton2006}.
\end{itemize}

\section{Orthogonally Derived Approaches}\label{orth-test}
\orthTestIntro. While the use of a combination term can sometimes
make sense, such as when writing a paper or performing testing that focuses
on the intersection between two test approaches, they are sometimes given
the same ``weight'' as their atomic counterparts. For example, \citetISTQB{}
\multiAuthHelper{include} ``formal reviews'' and ``informal reviews'' in
\ifnotpaper their \else its \fi glossary as separate terms, despite their
definitions essentially boiling down to ``reviews that follow (or do not
follow) a formal process'', which do not provide any new information.
These approaches are simply the combinations of ``reviews'' with ``formal''
and ``informal testing'', respectively. If a source describes an orthogonally
derived approach in more detail, such as security audits, we record it as a
distinct approach in \ourApproachGlossary{} with its related information.
Otherwise, we consider it out of scope since its details are captured by its
in-scope subapproaches. The following are examples of these orthogonally
derived approaches, most of which are out of scope:

\begin{enumerate}
    \item Black box conformance testing \citep[p.~25]{JardEtAl1999}
          %   (combining black box and conformance testing)
          % Specification-based: Technique (IEEE, 2022, p. 22; 2021, p. 8; Washizaki, 2024, p. 5-10; Hamburg and Mogyorodi, 2024; Souza et al., 2017, p. 3; Firesmith, 2015, pp. 46-47; Sakamoto et al., 2013, p. 344; implied by IEEE, 2022, pp. 2-4, 6-9)
          % Conformance: Type (implied by its quality (IEEE, 2017, p. 92; OG PMBOK 5th ed.))
    \item Black-box integration testing \citep[pp.~345\==346]{SakamotoEtAl2013}
          % Specification-based: Technique (IEEE, 2022, p. 22; 2021, p. 8; Washizaki, 2024, p. 5-10; Hamburg and Mogyorodi, 2024; Souza et al., 2017, p. 3; Firesmith, 2015, pp. 46-47; Sakamoto et al., 2013, p. 344; implied by IEEE, 2022, pp. 2-4, 6-9)
          % Integration: Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; Washizaki, 2024, p. 5-7; Hamburg and Mogyorodi, 2024; Sakamoto et al., 2013, p. 343; Peters and Pedrycz, 2000, Tab. 12.3; van Vliet, 2000, p. 438; implied by Barbosa et al., 2006, p. 3)
          %           OR Technique (implied by Sharma et al., 2021, pp. 601, 603, 605-606)
    \item Checklist-based reviews \citepISTQB{}
          % Checklist-based: Practice (IEEE, 2022, p. 34), Technique (Hamburg and Mogyorodi, 2024)
          % Reviews: Approach
    \item Closed-loop HiL verification \citep[p.~6]{PreußeEtAl2012}
          % Closed Loop: Technique?
          % HiL: Out of Scope (hardware)
    \item Closed-loop protection system testing \citep[p.~331]{ForsythEtAl2004}
          % Closed Loop: Technique?
          % System: Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; 2017, p. 467; 2016, p. 4; Washizaki, 2024, p. 5-7; Hamburg and Mogyorodi, 2024; Sakamoto et al., 2013, p. 343; Peters and Pedrycz, 2000, Tab. 12.3; van Vliet, 2000, p. 439; implied by Barbosa et al., 2006, p. 3; Gerrard, 2000a, p. 13)
    \item Endurance stability testing \citep[p.~55]{Firesmith2015}
          % Endurance: Type (IEEE, 2013, p. 2; implied by Firesmith, 2015, p. 55)
          %         OR Technique (IEEE, 2021, p. 38)
          % Stability: Type (implied by its quality (IEEE, 2017, p. 434; OG ISO/IEC, 2009) and Firesmith, 2015, p. 55)
    \item End-to-end functionality testing (\citealp[p.~20]{IEEE2021c}; \citealp[Tab.~2]{Gerrard2000a})
          % End-to-end: Type (Hamburg and Mogyorodi, 2024)
          %          OR Technique (Firesmith, 2015, p. 47; Sharma et al., 2021, pp. 601, 603, 605-606)
          % Functionality: Type (implied by its quality (IEEE, 2017, p. 196); Firesmith, 2015, p. 53)
    \item Formal reviews (\citealpISTQB{}; \citealp[p.~12\=/14]{SWEBOK2024})
          % Formal: Technique (inferred from informal testing)
          % Reviews: Approach
    \item Grey-box integration testing \citep[p.~344]{SakamotoEtAl2013}
          % Grey-Box: Technique (IEEE, 2021, p. 8; Firesmith, 2015, pp. 46, 48; Sakamoto et al., 2013, p. 344)
          % Integration: Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; Washizaki, 2024, p. 5-7; Hamburg and Mogyorodi, 2024; Sakamoto et al., 2013, p. 343; Peters and Pedrycz, 2000, Tab. 12.3; van Vliet, 2000, p. 438; implied by Barbosa et al., 2006, p. 3)
          %           OR Technique (implied by Sharma et al., 2021, pp. 601, 603, 605-606)
    \item Incremental integration testing \citep[pp.~601, 603, 605\==606]{SharmaEtAl2021}\todo{OG [19]}
          % Incremental: Practice?
          % Integration: Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; Washizaki, 2024, p. 5-7; Hamburg and Mogyorodi, 2024; Sakamoto et al., 2013, p. 343; Peters and Pedrycz, 2000, Tab. 12.3; van Vliet, 2000, p. 438; implied by Barbosa et al., 2006, p. 3)
          %           OR Technique (implied by Sharma et al., 2021, pp. 601, 603, 605-606)
    \item Informal reviews (\citealpISTQB{}; \citealp[p.~12\=/14]{SWEBOK2024})
          % Informal: Technique (implied by Kam, 2008, p. 6)
          % Reviews: Approach
    \item Infrastructure compatibility testing \citep[p.~53]{Firesmith2015}
          % Infrastructure: Type (implied by Firesmith, 2015, p. 57)
          %              OR Level (implied by Gerrard, 2000a, p. 13; see \Cref{tab:ieeeCats})
          % Compatibility: Type (IEEE, 2022, pp. 3, 22; 2021, p. 37, Tab. A.1; 2013, p. 2; implied by its quality (ISO/IEC, 2023a); Firesmith, 2015, p. 53)
    \item Invariant-based automatic testing \citep[pp.~184\==185, Tab.~21]{DoğanEtAl2014},
          including for ``AJAX user interfaces'' \citetext{p.~191}
          % Assertion Checking: Practice?
          % Automated: Practice (IEEE, 2022, pp. 20, 22)
          %         OR Technique (implied by p. 35)
    \item Legacy system integration (testing)\qtodo{Is this orthogonal? Investigate legacy testing} \citep[Tab.~2]{Gerrard2000a}
          % Legacy: Approach
          % System Integration: Level (IEEE, 2022, pp. 12, 22; 2021, p. 6; Hamburg and Mogyorodi, 2024)
    \item Manual procedure testing \citep[p.~47]{Firesmith2015}
          % Manual: Practice (IEEE, 2022, p. 22)
          %      OR Technique (implied by p. 35)
          % Procedure: Type (IEEE, 2022, pp. 7, 22; 2021, p. 39, Tab. A.1; 2017, p. 337; OG IEEE, 2013)
          %         OR Technique (implied by Firesmith, 2015, p. 47)
    \item Manual security audits \citep[p.~28]{Gerrard2000b}
          % Manual: Practice (IEEE, 2022, p. 22)
          %      OR Technique (implied by p. 35)
          % Security Audits: Technique (IEEE, 2021, p. 40)
          %               OR Type (inferred from security testing)
    \item Model-based GUI testing (\citealp[Tab.~1]{DoğanEtAl2014}; implied by \citealp[p.~356]{SakamotoEtAl2013})
          % Model-based: Practice (IEEE, 2022, p. 22; 2021, p. viii)
          %           OR Technique (Engström and Petersen, 2015, pp. 1-2; Kam, 2008, p. 4; implied by IEEE, 2022, p. 32; 2021, p. 7; 2017, p. 469)
          % GUI: Approach
    \item Model-based web application testing (implied by \citealp[p.~356]{SakamotoEtAl2013})
          % Model-based: Practice (IEEE, 2022, p. 22; 2021, p. viii)
          %           OR Technique (Engström and Petersen, 2015, pp. 1-2; Kam, 2008, p. 4; implied by IEEE, 2022, p. 32; 2021, p. 7; 2017, p. 469)
          % Web Application: Approach
    \item Non-functional search-based testing \citep[Tab.~1]{DoğanEtAl2014}
          % Non-functional: Approach
          % Search-based: Technique (Engström and Petersen, 2015, pp. 1-2)
    \item Offline MBT \citepISTQB{}
          % Offline: Practice?
          % Model-based: Practice (IEEE, 2022, p. 22; 2021, p. viii)
          %           OR Technique (Engström and Petersen, 2015, pp. 1-2; Kam, 2008, p. 4; implied by IEEE, 2022, p. 32; 2021, p. 7; 2017, p. 469)
    \item Online MBT \citepISTQB{}
          % Online: Practice?
          % Model-based: Practice (IEEE, 2022, p. 22; 2021, p. viii)
          %           OR Technique (Engström and Petersen, 2015, pp. 1-2; Kam, 2008, p. 4; implied by IEEE, 2022, p. 32; 2021, p. 7; 2017, p. 469)
    \item Role-based reviews\qtodo{Is this orthogonal? Investigate role-based testing} \citepISTQB{}
          % Role-based: Practice?
          % Reviews: Approach
    \item Scenario walkthroughs\qtodo{Is this orthogonal? Investigate scenario-based testing} \citep[Fig.~4]{Gerrard2000a}
          % Scenario: Technique (IEEE, 2022, pp. 9, 22; 2021, pp. 5, 8, 20, Fig. 2; 2017, p. 400; OG 2013; Washizaki, 2024, p. 5-12; Firesmith, 2015, p. 47; Sangwan and LaPlante, 2006, p. 26)
          % Walkthroughs: Technique (IEEE, 2017, p. 508)
    \item Scenario-based\qtodo{Is this orthogonal? Investigate scenario-based testing} reviews \citepISTQB{}
          % Scenario-based: Approach
          % Reviews: Approach
    \item Security attacks \citepISTQB{}
          % Security: Type (IEEE, 2022, pp. 9, 22, 26-27; 2021, pp. 7, 40, Tab. A.1; 2017, p. 405; OG 2013; implied by its quality (ISO/IEC, 2023a; Washizaki, 2024, p. 13-4); Firesmith, 2015, p. 53)
          % Attacks: Practice (IEEE, 2022, p. 34)
          %       OR Technique (implied by Hamburg and Mogyorodi, 2024)
    \item Security audits (\citealp[p.~40]{IEEE2021c}; \citealp[p.~28]{Gerrard2000b})
          % Security: Type (IEEE, 2022, pp. 9, 22, 26-27; 2021, pp. 7, 40, Tab. A.1; 2017, p. 405; OG 2013; implied by its quality (ISO/IEC, 2023a; Washizaki, 2024, p. 13-4); Firesmith, 2015, p. 53)
          % Audits: Practice?
    \item Statistical web testing \citep[p.~185]{DoğanEtAl2014}
          % Statistical: Technique (Kam, 2008, pp. 23, 48)      
          % Web Application: Approach
    \item Usability test script(ing) \citepISTQB{}
          % Usability: Type (IEEE, 2022, pp. 22, 26-27; 2021, pp. 7, 40, Tab. A.1; implied by its quality; Firesmith, 2015, p. 53)
          % Scripted: Practice (IEEE, 2022, pp. 20, 22; implied by p. 33)
    \item Web application regression testing \cite[Tab.~21]{DoğanEtAl2014}
          % Web Application: Approach
          % Regression: Technique (implied by IEEE, 2022, p. 35)
          %          OR Level (implied by Barbosa et al., 2006, p. 3)
    \item White-box unit testing \citep[pp.~345\==346]{SakamotoEtAl2013}
          % Structure-based: Technique (IEEE, 2022, p. 22; 2021, p. 8; Washizaki, 2024, pp. 5-10, 5-13; Hamburg and Mogyorodi, 2024; Firesmith, 2015, pp. 46, 49; Sakamoto et al., 2013, p. 344; implied by IEEE, 2022, pp. 2, 4, 6, 9; Barbosa et al., 2006, p. 3)
          % Unit: Level (IEEE, 2022, pp. 12, 20-22, 26-27; 2021, p. 6; 2017, p. 467; 2016, p. 4; Washizaki, 2024, p. 5-6; Hamburg and Mogyorodi, 2024; Sakamoto et al., 2013, p. 343; Peters and Pedrycz, 2000, Tab. 12.3; van Vliet, 2000, p. 438; implied by Barbosa et al., 2006, p. 3)
          %    OR Technique (implied by Engström and Petersen, 2015, pp. 1-2)
\end{enumerate}

% \citet{JardEtAl1999} \multiAuthHelper{use} the phrases ``local synchronous
% testing'' and ``remote asynchronous testing''. While these can be
% decomposed, for example, into local testing and synchronous testing,
% the two resulting approaches may not be orthogonal, potentially even having
% a parent-child relation (defined in \Cref{par-chd-rels}).

There are some cases where the subapproaches of the ``compound'' approaches
listed previously are \emph{not} from separate categories. However, these cases
can be explained by insufficient data or by edge cases that require special care.
While we assume that the categories given in \Cref{tab:ieeeCats} are
orthogonal, further analysis may disprove this. For now, all of these special
cases are affected by at least one of the following conditions:
\begin{enumerate}
    \item \textbf{At least one subapproach is categorized inconsistently.}
          When a subapproach has more than one category (see \Cref{multiCats}),
          it is unclear which one should be used to assess orthogonality.
    \item \textbf{At least one subapproach's category is inferred.} When the category
          of a test approach is not given by the literature but is inferred
          from related context (see \Cref{infers}), it is unclear if it can
          be used to assess orthogonality.
    \item \textbf{At least one subapproach is only categorized as an approach.}
          Since ``approach'' is a catch-all categorization, it does not
          need to be orthogonal to its subcategories.
    \item \textbf{A subapproach is explicitly based on another in the same
              category.} An example of this is stability testing, which
          tests a ``property that an object has with respect to a given
          failure mode if it cannot exhibit that failure mode''
          \citep[p.~434\todo{OG ISO/IEC, 2009}]{IEEE2017}. This notion of
          ``property'' is similar to that of ``quality'' that the test type
          category is built on, so it is acceptable that is implied to be
          a test type by its quality \citep[p.~434]{IEEE2017}%
          \todo{OG ISO/IEC, 2009} and by \citet[p.~55]{Firesmith2015}.
\end{enumerate}