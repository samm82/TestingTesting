\begin{enumerate}
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021a} {Firesmith2015} | {IEEE2017} {SWEBOK2025} {BarbosaEtAl2006} | {vanVliet2000}
          Regression testing and retesting are sometimes given as two distinct
          approaches (\citealp[p.~8]{IEEE2022}; \citeyear[p.~3]{IEEE2021a};
          \citealp[p.~34]{Firesmith2015}), but sometimes regression testing is
          defined as a form of ``selective retesting'' (\citealp[p.~372]{IEEE2017};
          \citealp[pp.~5\=/8, 6\=/5, 7\=/5]{SWEBOK2025};
          \citealp[p.~3]{BarbosaEtAl2006}). Moreover, the two possible variations
          of regression testing given by \citet[p.~411]{vanVliet2000} are
          ``retest-all'' and ``selective retest''\todo{Are these separate
              approaches?}, which is possibly the source
          of the above misconception. This creates a cyclic
          relation between regression testing and selective retesting.
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021c} {IEEE2017} {ISO_IEC2011} | {IEEE2022}
          % Assertion: {Firesmith2015}
          Accessibility testing is a subtype of usability testing
          (\citealp[p.~1]{IEEE2022}; \citeyear[Tab.~A.1]{IEEE2021c};
          \citeyear[p.~6]{IEEE2017}; \citealp{ISO_IEC2011};
          \citealp[p.~58]{Firesmith2015}) but these two test types are listed
          at the same level by \citet[Fig.~2]{IEEE2022}.
    \item % Flaw count (WRONG, DEFS): {IEEE2022}
          \citet[p.~5]{IEEE2022} give fuzz testing the tag ``artificial
          intelligence''; while fuzz testing could certainly be implemented in
          this way, it does not seem to be a requirement.
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021b} {IEEE2021c} | ISTQB | {Firesmith2015}
          Integration testing, system testing, and system integration testing
          are all listed as separate test levels (\citealp[p.~12, Fig.~2]{IEEE2022};
          \citeyear[p.~41\==44, 46, 51, 58, 74]{IEEE2021b}; \citeyear[p.~6]{IEEE2021c}),
          but system integration testing is listed as a child of both
          integration testing \citepISTQB{} and system testing
          \citep[p.~23]{Firesmith2015}.
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021a} {IEEE2021c} {SWEBOK2025} ISTQB | ISTQB
          % Assertion: {vanVliet2000} {SakamotoEtAl2013}
          \citetISTQB{} define ``component integration testing'' as ``the
          integration testing of components''. This is consistent with the
          definition of ``integration testing''\---testing that ``verifies the
          interactions among \acs{sut} elements (for instance,
          \emph{components}, modules, or subsystems)'' as well as ``external
          interfaces'' (\citealp[p.~5\=/7]{SWEBOK2025}, emphasis added; similar
          in \citealp[p.~13]{IEEE2022}; \citeyear[p.~6]{IEEE2021a};
          \citeyear[p.~6]{IEEE2021c}; \citealp[p.~438]{vanVliet2000};
          \citealp[p.~343]{SakamotoEtAl2013})\---which gives the former as a
          child of the latter. However, \citeposISTQB{} mind map of static and
          dynamic testing gives ``integration testing'' as a child of
          ``component integration testing'', inverting this relationship.
    \item % Flaw count (WRONG, LABELS): {IEEE2021c} | {IEEE2022} {IEEE2021c} {IEEE2013} {SWEBOK2025} {Firesmith2015} {Patton2006}
          % Flaw count (WRONG, LABELS): {IEEE2017} | {IEEE2022} {IEEE2021c} {IEEE2013} {SWEBOK2025} {Firesmith2015} {Patton2006}
          % Flaw count (WRONG, LABELS): {SWEBOK2014} {SWEBOK2025} | {IEEE2022} {IEEE2021c} {IEEE2013} {SWEBOK2025} {Firesmith2015} {Patton2006}
          % Flaw count (CONTRA, DEFS): {IEEE2021c} | {IEEE2017} | {SWEBOK2025} {SWEBOK2014}
          % Label error-guess
          Since the differences between the terms ``error'',
          ``fault'', ``failure'', and\linebreak ``defect'' are significant
          (see \Cref{error-fault-failure}), ``error guessing''---a term used by
          multiple sources \citep{IEEE2022,IEEE2021c,IEEE2013,SWEBOK2025,%
              Firesmith2015,Patton2006}---should either be called:
          \begin{itemize}
              \item ``defect guessing'' if it is based on a ``checklist of potential
                    defects'' \citep[p.~29]{IEEE2021c},
              \item ``failure guessing'' if it is based on ``the tester's knowledge
                    of past failures'' \citeyearpar[p.~165]{IEEE2017}, or
              \item ``fault guessing'' if it is a ``fault-based technique''
                    \citep[p.~4\=/9]{SWEBOK2014} that ``anticipate[s] the most
                    plausible faults in each \acs{sut}'' \citep[p.~5\=/13]{SWEBOK2025}.
          \end{itemize}
          % % This is a recommendation, and should be included later, if at all
          %   One (or multiple) of these proposed terms may be useful in tandem with
          %   ``error guessing'', which would focus on errors as traditionally defined
          %   and be a subapproach of error-based testing (implied by
          %   \citealp[p.~399]{vanVliet2000}).
    \item % Flaw count (WRONG, LABELS): {IEEE2024} {IEEE2010} | {IEEE2017} {Firesmith2015} {vanVliet2000}
          % Flaw count (WRONG, SYNS): {IEEE2024} {IEEE2010} | {IEEE2017} {vanVliet2000}
          % Flaw count (WRONG, SYNS): {vanVliet2000} | {vanVliet2000}
          % Assertion: {vanVliet2000}
          Since faults and errors are distinct (see \Cref{error-fault-failure}),
          ``fault seeding'' is not a synonym of ``error seeding''
          as claimed by \citet[p.~165]{IEEE2017} and
          \citet[p.~427]{vanVliet2000}. The term ``error seeding'', also
          used by \citet[p.~34]{Firesmith2015},
          should be abandoned in favour of ``fault seeding'' if it is defined
          as the ``process of intentionally adding known faults to those
          already in a computer program \dots{} [to] estimat[e] the number of
          faults remaining'' \citep[p.~165]{IEEE2017} based on the ratio
          between the number of new faults and the number of introduced faults
          that were discovered \citep[p.~427]{vanVliet2000}.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} {SWEBOK2025} {Firesmith2015} {PetersAndPedrycz2000} {AmmannAndOffutt2017} | {IEEE2022} {IEEE2021b} {Gerrard2000a}
          % Label static-test-flaw 
          ``Software testing'' is often defined to exclude static testing
          (\citealp[p.~13]{Firesmith2015}; \citealp[p.~439]{PetersAndPedrycz2000};
          \citealp[p.~222]{AmmannAndOffutt2017}), restricting ``testing'' to
          mean ``dynamic validation'' \citep[p.~5\=/1]{SWEBOK2025} or verification
          ``in which a system or component is executed'' \citep[p.~427]{IEEE2017}.
          However, ``terminology is not uniform among different communities, and
          some use the term `testing' to refer to static techniques%
          \notDefDistinctIEEE{technique} as well'' \citep[p.~5\=/2]{SWEBOK2025}.
          This is done by \citeauthor{IEEE2022} (\citeyear[pp.~16\==17]{IEEE2022};
          \citeyear[p.~43]{IEEE2021b}) and \citet[pp.~8\==9]{Gerrard2000a},
          although the former authors explicitly \emph{exclude} static testing
          in another document \citeyearpar[p.~440]{IEEE2017}!
    \item % Flaw count (CONTRA, CATS): {IEEE2021b} | {IEEE2022}
          \citeauthor{IEEE2021b} categorize static testing as a test level in
          \citeyearpar[p.~43]{IEEE2021b} but give it its own test approach
          category in \citeyearpar[p.~10, 23, Fig.~2]{IEEE2022}.
    \item % Flaw count (CONTRA, DEFS): {ISO_IEC2023a} | {IEEE2017}
          \citet{ISO_IEC2023a} and \citet[p.~196]{IEEE2017} both say that
          functional suitability is ``concerned with whether the functions meet
          stated and implied needs'', but the former includes ``the functional
          specification'' as part of its scope while the latter explicitly
          excludes it.
    \item % Flaw count (WRONG, SYNS): {IEEE2017} {ISO_IEC2023a} ISTQB | ISTQB
          ``Functionality'' is defined as the ``capabilities of the various
          \dots\ features provided by a product'' \citep[p.~196]{IEEE2017}
          while ``functional suitability'' refers to the ``capability of a
          product to provide [specified] functions'' (\citealp{ISO_IEC2023a};
          similar in \citealp[p.~196]{IEEE2017}; \citealpISTQB{}). However,
          \citetISTQB{} say these terms are synonyms, despite the former
          focusing on the \emph{capabilities} of a product's features as
          opposed to simply their \emph{provision} as outlined by the latter.
          %   It should likely instead be a synonym of its child ``functional
          %   correctness'', which is the ``capability of a product to provide
          %   accurate [and precise] results when used by intended users''
          %   \citep{ISO_IEC2023a}, of ``feature-based testing'' or ``features
          %   testing'', which are mentioned by not defined by \citet[p.~28]{Firesmith2015}
          %   and \citet[Fig.~5]{Gerrard2000a}, respectively, or of ``functions
          %   testing'', which is implied to exist by \citet[Tab.~11]{DoğanEtAl2014}.
    \item % Flaw count (MISS, PARS): {IEEE2021c}
          % Flaw count (MISS, LABELS): {IEEE2021c}
          % Assertion: {Reid1996}
          \citet{IEEE2021c} cite \citet{Reid1996} as the source for their
          Fig.~F.1 but they omit \acf{lcsaj} testing with no explanation, both
          from this figure and from the document as a whole. They label the
          figure as a ``partial ordering'', which might explain its omission
          from Fig.~F.1, but \citet[p.~7]{Reid1996} already identifies that his
          hierarchy is incomplete as ``it relates only a subset of the
          available test completion criteria, so other criteria \dots{} should
          still be considered''.
    \item % Flaw count (REDUN, DEFS): {IEEE2021c} | {IEEE2021c}
          \citet[p.~4]{IEEE2021c} define ``exit point'' as the ``last executable
          statement within a test item'', then later note that it ``is most
          commonly the last executable statement within the test item''.
    \item % Flaw count (CONTRA, SYNS): {IEEE2017} | {IEEE2017}
          \citet{IEEE2017} define both ``error'' \emph{and} ``mistake'' as
          ``human action[s] that produce[] an incorrect result''
          \citetext{pp.~165, 278, respectively} but state that ``the fault
          tolerance discipline distinguishes between a human action
          (a mistake)\dots{} and the amount by which the result is incorrect
          (the error)'' \citetext{p.~278}. This makes ``error'' and ``mistake''
          simultaneously synonyms \emph{and} not synonyms!
    \item % Flaw count (CONTRA, SYNS): ISTQB | {BaresiAndPezzè2006}
          A component is an ``entity with discrete structure \dots\ within a
          system considered at a particular level of analysis''
          \citep{ISO_IEC2023b} and ``the terms module, component, and unit
          are often used interchangeably or defined to be subelements
          of one another in different ways depending upon the context'' with
          no standardized relationship \citep[p.~82]{IEEE2017}. For example,
          \citetISTQB{} define them as synonyms while
          \citet[p.~107]{BaresiAndPezzè2006} say ``components
          differ from classical modules for being re-used in different contexts
          independently of their development''.
          % Flaw count (AMBI, DEFS): {IEEE2017} ISTQB
          Additionally, since components are structurally, functionally, or
          logically discrete \citep[p.~419]{IEEE2017} and ``can be tested in
          isolation'' \citepISTQB{}, ``unit/component/module testing'' could
          refer to the testing of both a module \emph{and} a specific function
          in a module, introducing a further level of ambiguity.
          % \thesisissuetodo{14}
    \item % Flaw count (OVER, SYNS): {IEEE2017} {IEEE2013} | {IEEE2022} {IEEE2017} {Perry2006}
          % Label level-phase-syns
          \citeauthor{IEEE2017} \ifnotpaper
              (\citeyear[pp.~469, 470]{IEEE2017}; \citeyear[p.~9]{IEEE2013}) \else
              \cite[pp.~469, 470]{IEEE2017}, \cite[p.~9]{IEEE2013} \fi say that
          ``test level'' and ``test phase'' are synonyms, both meaning a
          ``specific instantiation of [a] test sub-process'', but they have
          other definitions as well. ``Test level'' can also
          refer to the scope of a test process; for example, ``across the whole
          organization'' or only ``to specific projects''
          \citeyearpar[p.~24]{IEEE2022} and ``test phase'' can also refer to
          the ``period of time in the software life cycle'' when testing occurs
          \citeyearpar[p.~470]{IEEE2017}, usually after the implementation phase
          \citep[pp.~420, 509;][p.~56]{Perry2006}.
    \item % Flaw count (REDUN, PARS): {IEEE2017}
          \citet[p.~375]{IEEE2017} say that ``dependability characteristics
          include availability and its inherent or external influencing
          factors, such as availability''.
    \item % Flaw count (OVER, LABELS): {IEEE2010} | {IEEE2010}
          % Flaw count (WRONG, SYNS): implied by {IEEE2024} {IEEE2010} {IEEE2017} | implied by {IEEE2010}
          % Assertion: implied by {vanVliet2000}
          \citet[p.~128]{IEEE2010} define
          ``error'' as ``a human action that produces an incorrect result'',
          but also as ``an incorrect result'' itself. Since faults are inserted
          when a developer makes an error (\citealp[p.~36]{IEEE2024};
          \citealp[pp.~128, 140]{IEEE2010}; \citealp[pp.~399\==400]{vanVliet2000};
          implied by \citealp[p.~179]{IEEE2017}), this means that faults are
          \emph{also} ``incorrect results'', incorrectly implying that
          ``error'' and ``fault'' are synonyms.
    \item % Flaw count (OVER, LABELS): {IEEE2017} {IEEE2010} {SWEBOK2025}
          Besides being ``a human action that produces an incorrect
          result'' \citep[p.~128]{IEEE2010}, ``error'' can also be defined as
          the ``difference between a computed, observed, or measured value or
          condition and the true, specified, or theoretically correct value
          or condition'' (\citeyear[p.~165]{IEEE2017}; \citeyear[p.~128]{IEEE2010};
          similar in \citealp[pp.~17\=/18 to 17\=/19, 18\=/7 to 18\=/8]{SWEBOK2025}).
          While this is a widely used definition, particularly in mathematics,
          it makes some test approaches ambiguous.
          % Flaw count (AMBI, DEFS): {IEEE2017} {IEEE2010} {SWEBOK2025} | {IEEE2010} ISTQB
          For example, back-to-back testing is ``testing in which two or more
          variants of a program are executed with the same inputs, the outputs
          are compared, and errors are analyzed in case of discrepancies''
          (\citealp[p.~30]{IEEE2010}; similar in \citealpISTQB{}), which seems
          to refer to this definition of ``error''.
    \item % Flaw count (CONTRA, DEFS): {IEEE2021c} {IEEE2017} | {vanVliet2000} implied by {IEEE2021c}
          % Label c-use-def
          % TODO: SUPP DEFS?
          While a \acs{c-use} is defined as the ``use of the value of a
          variable in \emph{any} type of statement'' (\citealp[p.~2]{IEEE2021c};
          \citeyear[p.~83, emphasis added]{IEEE2017}), it is
          often qualified to \emph{not} be a \acs{p-use}
          (\citealp[p.~424]{vanVliet2000}; implied by \citealp[p.~27]{IEEE2021c}).
    \item % Flaw count (CONTRA, DEFS): {IEEE2021c} | {IEEE2017}
          % TODO: SUPP DEFS?
          \citeauthor{IEEE2021c} define an ``extended entry (decision) table''
          both as a decision table where the ``conditions consist of multiple
          values rather than simple Booleans'' \citeyearpar[p.~18]{IEEE2021c}
          and one where ``the conditions and actions are generally described
          but are incomplete'' \citeyearpar[p.~175]{IEEE2017}\todo{OG ISO1984}.
    \item % Flaw count (CONTRA, SYNS): {IEEE2021c} | implied by {IEEE2021c}
          % Flaw count (AMBI, PARS): {IEEE2021c}
          % Assertion: {Reid1996}
          \citet[Fig.~F.1]{IEEE2021c} is an adaptation of
          \citet[Fig.~2]{Reid1996} and one of the changes they make is
          replacing ``branch [coverage]'' with ``branch/decision coverage''.
          \citeauthor{Reid1996} notes that ``the term decision coverage is used
          interchangeably with that of branch coverage'' but that comparing one
          to the other is not a direct mapping (p.~4). \citeauthor{IEEE2021c}
          agree, saying ``branch and decision coverage are closely related%
          \dots{}, although lower levels of coverage may not be the same''
          \citeyearpar[p.~104]{IEEE2021c} and separating these two terms
          (Fig.~G.1, Secs.~5.3.2, 5.3.3, Annex~C.2.2\qtodo{What's the short
              form of ``annex''?}). However, (Fig.~F.1) implies that these
          terms are synonyms, contradicting this separation and making decision
          testing's relations ambiguous.
    \item % Flaw count (WRONG, LABELS): {IEEE2021c}
          A typo in \citet[Fig.~2]{IEEE2021c} means that ``specification-based
          techniques'' is listed twice, when the latter should be
          ``structure-based techniques''.
    \item % Flaw count (REDUN, PARS): {IEEE2017}
          \citet[p.~228]{IEEE2017} provide a definition for ``inspections and
          audits'', despite also giving
          definitions for ``inspection'' \citetext{p.~227} and ``audit''
          \citetext{p.~36}; while the first term \emph{could} be considered a
          superset of the latter two, this distinction doesn't seem useful.
    \item % Flaw count (WRONG, DEFS): {IEEE2017} | {IEEE2017}
          % TODO: SUPP DEFS?
          \citet{IEEE2017} use the same definition for ``partial correctness''
          \citetext{p.~314} and ``total correctness'' \citetext{p.~480}.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} | {IEEE2021c}
          % Assertion: {IEEE2021c} {vanVliet2000} {PetersAndPedrycz2000}
          \citepos[p.~83]{IEEE2017} definition of
          ``all-\acsp{c-use} testing''---testing that aims to execute all data
          ``use[s] of the value of a variable in any type of statement''---is
          \emph{much} more vague than the definition they give in
          (\citeyear[p.~27]{IEEE2021c}; similar in \citealp[p.~425]{vanVliet2000};
          \citealp[p.~479]{PetersAndPedrycz2000}): testing that exercises
          ``control flow sub-paths from each variable definition to each
          \acs{c-use} of that definition (with no intervening definitions)''.
    \item % Flaw count (WRONG, CATS): {IEEE2016} | {IEEE2022} {IEEE2016}
          % Label manual-or-keyword
          Since keyword-driven testing can be used in automated \emph{or} manual
          testing (\citealp[pp.~iii, vii, 6, 9, 29, 33, 35, 37]{IEEE2022};
          \citeyear[pp.~3\==6]{IEEE2016}), the claims that ``test cases can be
          either manual test cases or keyword test cases'' and ``a keyword test
          case implements a manual test case'' \citetext{p.~6} are incorrect.
          % Flaw count (WRONG, SYNS): implied by {IEEE2016} | {IEEE2022} {IEEE2016}
          These statements could also be interpreted as implying that
          ``keyword-driven testing'' is a synonym of ``automated testing'',
          which is also incorrect.
    \item % Flaw count (AMBI, DEFS): {IEEE2016} {IEEE2017} {IEEE2012} {vanVliet2000}
          % TODO: SUPP DEFS?
          % Assertion: {WikiHaskell2023}
          ``Data definition'' is defined as a ``statement where a variable is
          assigned a value'' (\citealp[p.~3]{IEEE2021c};
          \citeyear[p.~115]{IEEE2017}; similar in \citeyear[p.~27]{IEEE2012};
          \citealp[p.~424]{vanVliet2000}), but for functional programming
          languages such as Haskell with immutable variables
          \citep{WikiHaskell2023}, this could cause confusion and/or be
          imprecise.
    \item % Flaw count (CONTRA, CATS): {IEEE2022} | implied by {IEEE2022}
          \citet[p.~36]{IEEE2022} say ``A/B testing is not a test
          case generation technique as test inputs are not generated'', where
          ``test case generation technique'' may be a synonym of ``test design
          technique''. However, the inclusion of A/B testing under the heading
          ``Test design and execution'' in the same document implies that it
          may be considered a test technique.\footnote{For simplicity, this
              implied categorization as ``technique'' is omitted from
              \Cref{tab:multiCats}.}

          % STD | META
    \item % Flaw count (WRONG, CATS): {IEEE2022} {IEEE2021a} {IEEE2021c} {IEEE2017} | ISTQB
          \citetISTQB{} define ``test level'' as ``a specific instantiation of
          a test process'' which is vague and does not match \noHyperIEEE{}'s
          definition given in \Cref{tab:ieeeCats} and further discussed in
          \Cref{cats-def}.
    \item % Flaw count (AMBI, PARS): {Firesmith2015}
          While \citet{Firesmith2015} likely uses the hollow triangle to mean
          ``subtype'' (\distinctIEEE{type}) following \acf{uml} notation
          \PaigeMtgNote, he never explicitly specifies this notation.
    \item % Flaw count (CONTRA, PARS): {ISO_IEC2023a} | {Firesmith2015}
          % Label perf-sec-par
          \perfSecParFlaw{}
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021c} {SWEBOK2025} ISTQB | {Firesmith2015}
          Random testing is a subtechnique of specification-based testing
          (\citealp[pp.~7, 22]{IEEE2022}; \citeyear[pp.~5, 20, Fig.~2]{IEEE2021c};
          \citealp[p.~5\=/12]{SWEBOK2025}; \citealpISTQB{}) but
          \citet[p.~46]{Firesmith2015} lists them separately.
    \item % Flaw count (OVER, DEFS): {SWEBOK2025} | {IEEE2022}
          The \acs{swebok} V4 defines ``privacy testing'' as testing that
          ``assess[es] the security and privacy of users' personal data to
          prevent attacks'' \citep[p.~5\=/9]{SWEBOK2025}. This seems to
          overlap (both in scope and name) with the definition of ``security
          testing'' in \citep[p.~7]{IEEE2022}: testing
          ``conducted to evaluate the degree to which a test item, and
          associated data and information, are [sic] protected so that'' only
          ``authorized persons or systems'' can use them as intended.
    \item % Flaw count (CONTRA, DEFS): {SWEBOK2025} {Patton2006} | {IEEE2017}
          % Label path-test
          Path testing ``aims to execute all entry-to-exit control flow paths
          in a \acs{sut}'s control flow graph'' (\citealp[p.~5\=/13]{SWEBOK2025};
          similar in \citealp[p.~119]{Patton2006}), but \citet[p.~316]{IEEE2017}
          add that it can also be ``designed to execute \dots{} selected paths.''
    \item % Flaw count (CONTRA, DEFS): {IEEE2022} | ISTQB
          % Label tour-def
          % Label tour-def-contra
          \tourFlaw{} \appDiffs{tours}
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} | {SWEBOK2025} | ISTQB
          % Label alpha-def
          \alphaFlaw{} \appDiffs{alpha testing}
    \item % Flaw count (CONTRA, DEFS): {SWEBOK2025} | {IEEE2017}
          % Assertion: {JardEtAl1999}
          % Flaw count (OVER, DEFS): {SWEBOK2025} | ISTQB {Firesmith2015}
          % Flaw count (AMBI, SYNS): {Kam2008} | ISTQB {Firesmith2015}
          % Flaw count (REDUN, DEFS): {Kam2008}
          ``Conformance testing'' is defined by \citet[p.~5\=/7]{SWEBOK2025} as
          testing that ``aims to verify that the \acs{sut} conforms to
          standards, rules, specifications, requirements, design, processes, or
          practices'', but this disagrees with the definition given by the
          \citet[p.~523]{PMBOK2013}: testing that evaluates the degree to which
          ``results \dots{} fall within the limits that define acceptable
          variation for a quality requirement''. \citeauthor{SWEBOK2025}'s
          definition instead seems to correspond to the definition of
          compliance testing given by \citetISTQB{}\todo{OG IREB Glossary} and
          \citet[p.~33]{Firesmith2015}, which may explain why
          \citet[p.~43]{Kam2008} gives them as synonyms (along with his
          unhelpful definition of compliance testing: ``testing to determine
          the compliance of the component or system'').
    \item % Flaw count (AMBI, LABELS): {IEEE2017} | {Firesmith2015} | {Firesmith2015} {Gerrard2000a}
          The distinctions between development testing \citep[p.~136]{IEEE2017},
          developmental testing \citep[p.~30]{Firesmith2015}, and developer
          testing \citep[p.~39;][p.~11]{Gerrard2000a} are unclear and seem
          miniscule.\todo{Is this a def flaw?}
    \item % Flaw count (AMBI, DEFS): ISTQB
          % TODO: SUPP DEFS?
          \citetISTQB{} define
          ``\acf{ml} model testing'' and ``\acs{ml} functional performance''
          in terms of ``\acs{ml} functional performance criteria'',
          which is defined in terms of ``\acs{ml} functional performance
          metrics'', which is defined as ``a set of measures that relate to the
          functional correctness of an \acs{ml} system''. The use
          of ``performance'' (or ``correctness'') in these definitions is at
          best ambiguous and at worst incorrect.
    \item % Flaw count (WRONG, SCOPE): {IEEE2022} {IEEE2021c} {IEEE2017} | {SWEBOK2025}
          \qualImprovFlaw{}
    \item % Flaw count (CONTRA, SYNS): ISTQB implied by {IEEE2015} | {SWEBOK2025}
          % Assertion: implied by {Gerrard2000a}
          % Label stage-level-syns
          The terms ``test level'' and ``test stage'' are given as synonyms
          (\citealpISTQB{}; implied by \citealp[p.~9]{IEEE2015};
          \citealp[p.~9]{Gerrard2000a}), but
          \citet[p.~5\=/6]{SWEBOK2025} says ``[test] levels can be distinguished
          based on the object of testing, the \emph{target}, or on the purpose
          or \emph{objective}'' and calls the former ``test stages'', giving
          the term a child relation (see \Cref{par-chd-rels}) to ``test level''
          instead. However, the examples of ``test stages'' listed---unit
          testing, integration testing, system testing, and acceptance testing
          \citep[pp.~5\=/6 to 5\=/7]{SWEBOK2025}---are commonly categorized as
          ``test levels'' (see \Cref{cats-def}).
    \item % Flaw count (WRONG, SCOPE): {Firesmith2015}
          % Assertion: {LiuEtAl2023} {MorgunEtAl1999} {HolleyEtAl1996} {HoweAndJohnson1995}
          % Label assert-truth
          \tolTestFlaw{}
    \item % Flaw count (OVER, LABELS): {SWEBOK2025} implied by {Valcheva2013} {YuEtAl2011} | {Firesmith2015}
          ``Orthogonal array testing'' (\citealp[pp.~5\=/1, 5\=/11]{SWEBOK2025};
          implied by \citealp[pp.~467, 473]{Valcheva2013};
          \citealp[pp.~1573\==1577, 1580]{YuEtAl2011}) and ``operational
          acceptance testing'' \citep[p.~30]{Firesmith2015} have the same
          acronym (``OAT'').
    \item % Flaw count (CONTRA, SYNS): {SWEBOK2025} | {Firesmith2015}
          ``Pair testing'' and ``buddy testing'' are synonyms
          \citep[p.~5\=/14]{SWEBOK2025} but \citet[pp.~36, 39]{Firesmith2015}
          lists them separately.
    \item % Flaw count (CONTRA, SYNS): ISTQB | {Firesmith2015}
          % Label oat-pat-syns
          \citetISTQB{} give ``operational acceptance testing'' and
          ``production acceptance testing'' as synonyms, but
          \citet[p.~30]{Firesmith2015} lists them separately.
    \item % Flaw count (AMBI, DEFS): {IEEE2017} {IEEE2010} {SWEBOK2025} | {SWEBOK2025}
          % Assertion: {vanVliet2000}
          While ``error'' is defined as a ``human action that produces an
          incorrect result'' (\citealp[p.~165]{IEEE2017};
          \citeyear[p.~128]{IEEE2010}; \citealp[p.~12\=/3]{SWEBOK2025}%
          \footnote{\citet[p.~12\=/3]{SWEBOK2025} references the definition
              given in \citet[p.~165]{IEEE2017}; while we would usually omit
              the former in favour of the original source, we include it here
              as an example of a flaw within a document.};
          \citealp[p.~399]{vanVliet2000}), \citeauthor{SWEBOK2025} does not use
          this consistently, sometimes implying that errors can be instrinsic
          to software itself \citeyearpar[pp.~4\=/9, 6\=/5, 7\=/3, 12\=/4,
              12\=/9, 12\=/13]{SWEBOK2025}.\qtodo{I ignore ``syntax errors,
              runtime errors, and logical errors'' \citep[p.~16\=/13, cf.
                  p.~18\=/13]{SWEBOK2025} since they seem to be in different
              domains. Does that make sense? How should I document this?}
    \item % Flaw count (CONTRA, LABELS): {IEEE2024} {IEEE2019a} {SWEBOK2025} {Lyu1996} | {SWEBOK2025}
          % Assertion: {vanVliet2000}
          \refHelper{} \citet[p.~1\=/1]{SWEBOK2025} defines ``defect'' as ``an
          observable difference between what the software is intended to do and
          what it does'', but this seems to instead match the definition of
          ``failure'': the inability of a system ``to perform a required
          function or \dots{} within previously specified limits'' that is
          ``externally visible'' (\citealp[p.~7]{IEEE2019a}; similar in
          \citealp[pp.~15, 37]{IEEE2024}; \citealp[p.~5\=/3]{SWEBOK2025};
          \citealp[p.~12]{Lyu1996}; \citealp[p.~400]{vanVliet2000}).
    \item % Flaw count (AMBI, LABELS): {IEEE2024} {IEEE2010} | {SWEBOK2025}
          % Flaw count (CONTRA, LABELS): {IEEE2024} {IEEE2010} {SWEBOK2025} | implied by {SWEBOK2025}
          % Assertion: {Lyu1996} {vanVliet2000}
          \citet[p.~4\=/11]{SWEBOK2025} says ``\emph{fault tolerance}
          is a collection of techniques that increase software reliability by
          detecting errors and then recovering from them or containing their
          effects if recovery is not possible''. Since errors and faults are
          distinct (see \Cref{error-fault-failure}), this should either be
          called ``\emph{error} tolerance'' or be described as ``detecting
          \emph{faults}''. % The intent of this term-definition pair is unclear,
          %   as the strategies given---``backing up and retrying, using auxiliary
          %   code and voting algorithms, and replacing an erroneous value with a
          %   phony value that will have a benign effect''---could be used for
          %   errors \emph{or} faults.
          However, the notion of ``detecting errors and then \emph{recovering
              from them} or containing their effects if recovery is not
          possible'' seems to imply that \citet[p.~4\=/11, emphasis added]{SWEBOK2025}
          is really talking about \emph{failures}: the visible effects of
          faults (\citealp[pp.~15, 37]{IEEE2024}; \citealp[p.~5\=/3]{SWEBOK2025};
          \citealp[p.~12]{Lyu1996}; \citealp[p.~400]{vanVliet2000}).
    \item % Flaw count (REDUN, LABELS): {SWEBOK2025}
          % Assertion: {Gerrard2000b}
          % Label ethical-hacking
          Including ``testing'' in the term ``ethical hacking test[ing]''
          \citep[p.~13\=/5]{SWEBOK2025} is redundant since the clearer term
          ``ethical hacking'' used by \citet[p.~28]{Gerrard2000b} already
          indicates that this is an activity to be performed.
    \item % Flaw count (CONTRA, CATS): {IEEE2022} {IEEE2021a} {IEEE2021b} | ISTQB
          % Flaw count (CONTRA, CATS): {IEEE2022} {IEEE2021a} {IEEE2021b} | {BarbosaEtAl2006}
          % Don't double count "ISTQB | {Lyu1996} {BarbosaEtAl2006}" multiCat flaw
          % Flaw count (AMBI, CATS): {IEEE2022} {IEEE2021c} {IEEE2017} {SWEBOK2025} ISTQB {KuļešovsEtAl2013} {Perry2006} {PetersAndPedrycz2000} {Gerrard2000a} | {BarbosaEtAl2006}
          % Flaw count (AMBI, CATS): {IEEE2022} {IEEE2021c} {IEEE2017} | {IEEE2022} {IEEE2021a} {IEEE2021b}
          % Assertion: {SWEBOK2025} ISTQB {KuļešovsEtAl2013} {Perry2006} {PetersAndPedrycz2000} {Gerrard2000a}
          Retesting and regression testing seem to be categorized separately
          from the rest of the test approaches (\citealp[pp.~15, 23]{IEEE2022};
          \citeyear[p.~8]{IEEE2021a}; \citeyear[p.~4]{IEEE2021b}) but this is
          not justified. \citetISTQB{} consider regression testing to be a test
          type while \citet[p.~532]{Lyu1996} and \citet[p.~3]{BarbosaEtAl2006}
          consider it a test level;
          since it is not included as an example of a test level by the sources
          that describe them (see \Cref{cats-def}), this latter categorization
          is likely not universal at best and incorrect at worst.
    \item % Flaw count (AMBI, DEFS): ISTQB
          While ergonomics testing is out of scope (as it tests hardware, not
          software; see \Cref{hard-test}), its definition of ``testing to
          determine whether a component or system and its input devices are
          being used properly with correct posture'' \citepISTQB{} seems to
          focus on how the system is \emph{used} as opposed to the system
          \emph{itself}.
    \item % Flaw count (AMBI, DEFS): ISTQB
          \citetISTQB{} define ``end-to-end testing'' as testing ``in which
          business processes are tested from start to finish under
          production-like circumstances'', but it is unclear whether this tests
          the business processes \emph{themselves} or the \emph{system} that
          performs them.
    \item % Flaw count (AMBI, DEFS): ISTQB
          % Flaw count (AMBI, TRACE): ISTQB
          % Assertion: {SPICE2022}
          \citetISTQB{} describe the term ``software in the loop'' as a kind of
          testing, while the source they reference seems to
          describe ``Software-in-the-Loop-Simulation'' as a ``simulation
          environment'' that may support software integration testing
          \citep[p.~153]{SPICE2022}; is this a test approach or a tool
          that supports testing?
    \item % Flaw count (WRONG, SCOPE): {IEEE2022} | ISTQB
          % Label specific-istqb-a
          Mathematical-based testing is a test practice based on ``the test
          item's required behaviour, input space or output space'' when they
          ``can be described in sufficient detail'' \citep[p.~36]{IEEE2022}.
          However, \citetISTQB{} define ``math testing'' as ``testing to
          determine the correctness of the pay table implementation, the random
          number generator results, and the return to player computations''.
          While these are all subsets of mathematical-based testing, this
          definition is likely taken from a particular case study or test item,
          making its scope too narrow for it to be widely useful.
    \item % Flaw count (WRONG, SCOPE): ISTQB
          % Label specific-istqb-b
          \citetISTQBemph{} define ``multiplayer testing'' as ``testing to
          determine if many players can simultaneously interact with the
          \emph{casino} game world, \dots{} computer-controlled opponents, game
          servers, and \dots{} each other based on the game design''. This
          definition sheds light on the particular test item they use to define
          ``math testing'' (see \flawref{specific-istqb-a}); omitting the word
          ``casino'' would make this definition apply more widely.
    \item % Flaw count (REDUN, DEFS): ISTQB
          \citetISTQB{} define ``specification-based testing'' circularly as
          ``testing based on an analysis of the specification of the component
          or system''.
    \item % Flaw count (WRONG, SCOPE): ISTQB
          % Assertion: {Bluejay2024}
          % Label par-sheet-test
          \parSheetTestFlaw{}
    \item % Flaw count (WRONG, TRACE): ISTQB
          % Flaw count (WRONG, LABELS): {NIST2023} | ISTQB
          \citetISTQB{} cite \citet{NIST2019} for their\linebreak definition of
          ``security attack'', but this source does not provide one.\linebreak
          Another standard by the same organization---the \acf{nist}---provides
          a similar definition for the term ``attack'' \citep[p.~160]{NIST2023}
          as opposed to ``security attack''.
    \item % Flaw count (WRONG, TRACE): ISTQB
          \citetISTQB{} cite \citet{ISO_IEC2020} for their definition of
          ``visual testing'', but this source does not provide one.
    \item % Flaw count (WRONG, TRACE): ISTQB
          % Assertion: {KoomenEtAl2006}
          \citetISTQB{} incorrectly list ``M.~Koomen'' as an author of
          \citet{KoomenEtAl2006}, when the correct author name is ``Tim Koomen''
          and should therefore be cited as ``T.~Koomen''.
    \item % Flaw count (WRONG, SYNS): ISTQB
          % Assertion: {Reid1996}
          \citet[p.~4]{Reid1996} says ``the use of the term `condition' in
          branch condition testing can mislead the reader into thinking all
          conditions are exercised'', which \citetISTQB{} seem to do by giving
          ``condition coverage'' as a synonym of ``branch condition coverage''.
    \item % Flaw count (AMBI, DEFS): {Firesmith2015} | {Firesmith2015}
          While model testing is said to test the object under test,
          it seems to describe testing the models themselves
          \citep[p.~20]{Firesmith2015}; using the models to test the object
          under test seems to be called ``driver-based testing''
          \citetext{p.~33}.
    \item % Flaw count (AMBI, DEFS): {Firesmith2015}
          ``Tool/environment testing'' could ambiguously refer to either
          testing the tools/environment \emph{themselves} or \emph{using}
          them to test the object under test; the wording of its subtypes
          \citep[p.~25]{Firesmith2015} seems to imply the former.
    \item % Flaw count (MISS, DEFS): {Firesmith2015}
          The acronym for \acf{sos} \citep{IEEE2019b} is used but not defined
          by \citet[p.~23]{Firesmith2015}.
    \item % Flaw count (OVER, LABELS): {Firesmith2015} | {Firesmith2015}
          % Label cat-acro
          ``Customer acceptance testing'' and ``contract(ual) acceptance
          testing'' have the same acronym (``CAT'') \citep[p.~30]{Firesmith2015}.
    \item % Flaw count (OVER, LABELS): {Firesmith2015} | {Firesmith2015}
          % Label hil-acro
          ``Hardware-in-the-loop testing'' and ``human-in-the-loop testing''
          have the same acronym (``HIL'') \citep[p.~23]{Firesmith2015},
          % Flaw count (CONTRA, LABELS): {Firesmith2015} | {PreußeEtAl2012}
          although \citet[p.~2]{PreußeEtAl2012} use ``HiL'' for the former.
    \item % Flaw count (WRONG, TRACE): {DoğanEtAl2014}
          \citet[p.~184]{DoğanEtAl2014} claim that \citet{SakamotoEtAl2013}
          define ``prime path coverage'', but they do not.
    \item % Flaw count (AMBI, PARS): {PMBOK2013} | {PMBOK2013}
          The \citet[p.~244; similar on p.~535]{PMBOK2013} says ``quality
          assurance work will fall under the conformance work category in the
          cost of quality framework'', but (Fig.~8\=/2) suggests that
          ``conformance work'' is a part of quality assurance. This
          introduces ambiguity at best and creates a cyclic parent-child
          relation (which violates our definition in \Cref{par-chd-rels}%
          \qtodo{Should I be more specific?}) at worst.
    \item % Flaw count (MISS, LABELS): {PMBOK2013}
          The \citet[p.~476]{PMBOK2013} uses the acronym ``QA'' which is
          implied to refer to ``quality assurance'' as ``QC'' refers to
          ``quality control'' (p.~535), but they do not make this explicit.

          % META | TEXT
    \item % Flaw count (WRONG, TRACE): {PetersAndPedrycz2000} | {PetersAndPedrycz2000}
          % Label myers-citation
          \citet[pp.~438, 497]{PetersAndPedrycz2000} cite \citet{Myers1976}
          but misspell the author's name as ``Meyers'' in the References
          section of the relevant chapter (p.~500). This is especially
          confusing since they also include \citet{Myers1992} in the
          bibliography, which was written by a different author.
    \item % Flaw count (CONTRA, PARS): implied by {Patton2006} | {vanVliet2000}
          While \citet[p.~120]{Patton2006} implies that condition testing is a
          subtechnique of path testing, \citet[Fig.~13.17]{vanVliet2000} says
          that multiple condition coverage (which seems to be a synonym of
          condition coverage \citetext{p.~422}) does not subsume and is not
          subsumed by path coverage.
    \item % Flaw count (WRONG, SYNS): {IEEE2024} {IEEE2010} {vanVliet2000} | {Patton2006}
          % Flaw count (WRONG, SYNS): {Patton2006}
          % Label bug-patton
          The differences between the terms ``error'', ``fault'', ``failure'',
          and ``defect'' are significant (see \Cref{error-fault-failure}), but
          \bugPattonFlaw{} Not only does he set aside established conventions
          because of their negative connotations, including severity and blame
          (p.~14), he also includes ``feature'' in this list. This is likely
          because to his definition of ``bug'', which includes the case where
          ``the software does something that the product specification doesn't
          mention''; this means that ``an ambitious programmer'' who implements
          extra features is actually introducing bugs (p.~15). While this synonym
          relation holds in this specific case, not all features are bugs!
    \item % Flaw count (CONTRA, DEFS): {IEEE2022} | {Patton2006}
          % Label load-def
          \loadFlaw{} \appDiffs{load testing}
    \item % Flaw count (CONTRA, DEFS): {IEEE2021c} | {Patton2006}
          State testing requires that ``all states in the state model
          \dots\ [are] `visited'\,'' \citep[p.~19]{IEEE2021c}, but
          \citet[pp.~82\==83]{Patton2006} lists this as only one of its
          possible criteria.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} {PetersAndPedrycz2000} {vanVliet2000} | {Patton2006}
          System testing is ``conducted on a complete, integrated system''
          (\citealp[p.~456]{IEEE2017}; similar in \citealp[Tab.~12.3]{PetersAndPedrycz2000};
          \citealp[p.~439]{vanVliet2000}), but \citet[p.~109]{Patton2006}
          says it can also be done on ``at least a major portion'' of the product.
    \item % Flaw count (AMBI, SYNS): ISTQB | {Patton2006}
          % TODO: NEAR SYNS?
          \citetISTQB{} claim that code inspections are related to peer reviews
          but \citet[pp.~94\==95]{Patton2006} makes them quite distinct.
    \item % Flaw count (AMBI, PARS): {IEEE2017} | {Patton2006} implied by {IEEE2021c} {vanVliet2000}
          \citet[p.~119]{Patton2006} says that branch testing is ``the simplest
          form of path testing'' which is also implied by
          \citet[Fig.~F.1]{IEEE2021c} and
          \citet[p.~433]{vanVliet2000}. This is true in the example
          \citeauthor{Patton2006} gives, but is not necessarily generalizable;
          one could test the behaviour at branches without testing even a
          \emph{subset} of complete paths, which \citet[p.~316]{IEEE2017} give
          as a definition of ``path testing'' (see \flawref{path-test})!
    \item % Flaw count (CONTRA, SYNS): ISTQB | {PetersAndPedrycz2000}
          % Label walkthrough-syns
          ``Walkthroughs'' and ``structured walkthroughs'' are given
          as synonyms by \citetISTQB{} but \citet[p.~484]{PetersAndPedrycz2000}
          imply that they are different, saying a
          more structured walkthrough may have specific roles.
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | implied by {Patton2006}
          While \citet[p.~92\ifnotpaper, emphasis added\fi]{Patton2006}
          says that reviews are ``\emph{the} process[es] under which static
          white-box testing is performed'', \citet[pp.~418\==419]{vanVliet2000}
          gives correctness proofs as another example.
    \item % Flaw count (CONTRA, LABELS): {IEEE2021c} {IEEE2017} {PetersAndPedrycz2000} | {vanVliet2000}
          % Assertion: {Reid1996}
          % Label data-use-caps
          % TODO: SUPP LABELS?
          ``Computation data use'' and ``predicate data use'' are usually
          abbreviated as the lowercase ``\acs{c-use}'' and ``\acs{p-use}''
          (\citealp[pp.~3, 27\==29, 35\==36, 114\==155, 117\==118, 129]{IEEE2021c};
          \citeyear[p.~124]{IEEE2017}; \citealp[p.~477, Tab.~12.6]{PetersAndPedrycz2000};
          \citealp[Fig.~2]{Reid1996}), but \citet[pp.~424\==425]{vanVliet2000}
          uses the uppercase ``C\=/use'' and ``P\=/use'' instead.
    \item % Flaw count (CONTRA, LABELS): {IEEE2021c} {PetersAndPedrycz2000} | {vanVliet2000}
          % Assertion: {Reid1996}
          % TODO: SUPP LABELS?
          ``Definition\=/use path'' is usually abbreviated as the lowercase
          % Add \linebreak to prevent overhang of "ISO/IEC"
          ``\acs{du-path}''\linebreak (\citealp[pp.~3, 27, 29, 35, 119\==121, 129]{IEEE2021c};
          \citealp[pp.~478\==479]{PetersAndPedrycz2000}; \citealp[Fig.~2]{Reid1996}),
          but \citet[p.~425]{vanVliet2000} uses the uppercase ``DU\=/path'' instead.
    \item % Flaw count (MISS, DEFS): {IEEE2021c} {IEEE2017} {PetersAndPedrycz2000} implied by {vanVliet2000} | {vanVliet2000}
          \Citet[p.~425]{vanVliet2000} defines many types of data
          flow coverage, including all-\acsp{p-use},
          all-\acsp{p-use}/some-\acsp{c-use}, and
          all-\acsp{c-use}/some-\acsp{p-use}, but
          excludes all-\acsp{c-use}, which is implied by these definitions and
          defined elsewhere (\citealp[p.~27]{IEEE2021c};
          \citeyear[p.~83]{IEEE2017}; \citealp[p.~479]{PetersAndPedrycz2000}).
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | {IEEE2021c} {IEEE2017} {PetersAndPedrycz2000}
          \Citet[pp.~424\==425]{vanVliet2000} specifies that every
          successor of a data definition use needs to be executed as part of
          all-uses testing, but this condition is not included elsewhere
          (\citealp[pp.~28\==29]{IEEE2021c}; \citeyear[p.~120]{IEEE2017};
          \citealp[pp.~478\==479]{PetersAndPedrycz2000}).
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | {IEEE2021c} {IEEE2017} {SWEBOK2025} {PetersAndPedrycz2000}
          All-\acsp{du-path} testing is usually defined as exercising all
          ``loop-free control flow sub-paths from each variable definition to
          every use (both \acs{p-use} and \acs{c-use}) of that definition (with no
          intervening definitions)'' (\citealp[p.~29]{IEEE2021c}; similar in
          \citeyear[p.~125]{IEEE2017}; \citealp[p.~5\=/13]{SWEBOK2025};
          \citealp[p.~479]{PetersAndPedrycz2000}). However,
          \citet[p.~425]{vanVliet2000} says that paths containing simple cycles
          may also be required, in which case exercising all ``loop-free
          control flow sub-paths'' would be insufficient.
          % This was only a flaw when looking at IEEE2021c
          % \item % OUTDATED Flaw count (CONTRA, DEFS): {vanVliet2000} | implied by {Reid1996}
          %       \Citet[pp.~432\==433]{vanVliet2000} says that all-\acsp{p-use}
          %       testing is only stronger than all-edges (branch) testing if there are
          %       infeasible paths, but \citet[pp.~3, 6\==7]{Reid1996} only specifies
          %       this caveat implicitly.
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | {SWEBOK2025}
          \Citet[pp.~432\==433]{vanVliet2000} says that
          all-\acsp{du-path} testing is only stronger than all-uses testing if
          there are infeasible paths, but \citet[p.~5\=/13]{SWEBOK2025} does
          not specify this caveat.
    \item % Flaw count (WRONG, PARS): {IEEE2021c} {IEEE2017} {vanVliet2000} | implied by {PetersAndPedrycz2000}
          \citet[Fig.~12.31]{PetersAndPedrycz2000} \ifnotpaper imply \else
              implies \fi that decision coverage is a child of both \acf{c-use}%
          \footnote{\label{cap-note}See \flawref{data-use-caps}.} coverage
          \emph{and} \acf{p-use}\textsuperscript{\ref{cap-note}} coverage; this
          seems incorrect, since decisions are the result of \acsp{p-use} and
          \emph{not} \acsp{c-use} (\citealp[pp.~5, 27]{IEEE2021c};
          \citeyear[p.~332]{IEEE2017}; \citealp[p.~424]{vanVliet2000}), and
          only the \acs{p-use} relation is implied by \citet[Fig.~F.1]{IEEE2021c}.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} | {SWEBOK2014} | {vanVliet2000}
          Acceptance testing is ``usually performed by the purchaser \dots{}
          with the \dots{} vendor'' \citep[p.~5]{IEEE2017}, ``may or may not
          involve the developers of the system'' \citep[p.~4\=/6]{SWEBOK2014},
          and/or ``is often performed under supervision of the user
          organization'' \citep[p.~439]{vanVliet2000}; these descriptions
          of who the testers are contradict each other \emph{and} all introduce
          some uncertainty\qtodo{Does this merit counting this as an Ambiguity
              as well as a Contradiction?}
          (``usually'', ``may or may not'', and ``often'', respectively).

          % TEXT | PAPER
    \item % Flaw count (MISS, DEFS): {Bas2024}
          \citet[p.~16]{Bas2024} lists ``three [backup] location
          categories: local, offsite and cloud based [sic]'' but does not
          define or discuss ``offsite backups'' \citetext{pp.~16\==17}.
    \item % Flaw count (WRONG, SYNS): implied by {SharmaEtAl2021}
          \citet[p.~601]{SharmaEtAl2021} seem to use the terms ``grey-box
          testing'' and ``(stepwise) code reading'' interchangeably, which would
          incorrectly imply that they are synonyms\todo{FIND SOURCES}.
          % [Tracked automatically in Table C.2] (CONTRA, PARS): {SWEBOK2025} {Valcheva2013} implied by {Mandl1985} | implied by {Valcheva2013}
          % \citet[p.~473]{Valcheva2013} implies that ``pairwise testing'' is a
          % synonym of ``\acf{orthat}'', but it seems that it is instead a child
          % of \acs{orthat} (\citealp[p.~5\=/11]{SWEBOK2025}; implied by
          % \citealp[p.~1055]{Mandl1985}) which \citeauthor{Valcheva2013}
          % supports on the same page (p.~473)!
    \item % Flaw count (WRONG, SYNS): {IEEE2017} ISTQB {PetersAndPedrycz2000} {vanVliet2000} {SakamotoEtAl2013} | {Kam2008}
          \citet[p.~46]{Kam2008} gives ``program testing'' as a synonym of
          ``component testing'' but it would make more sense as a synonym of
          ``system testing'', which is conducted on the system, or program, as
          a whole (\citealp[p.~456\todo{OG 2012}]{IEEE2017}; \citealpISTQB{};
          \citealp[Tab.~12.3]{PetersAndPedrycz2000}; \citealp[p.~439]{vanVliet2000};
          \citealp[pp.~343\==344]{SakamotoEtAl2013}).
    \item % Flaw count (WRONG, SYNS): {SWEBOK2025} {vanVliet2000} | {Kam2008}
          \citet[p.~46]{Kam2008} gives ``mutation testing'' as a
          synonym of ``back-to-back testing''; while the two are related
          \citep[p.~30]{IEEE2010}, the variants used in mutation testing are
          generated or designed to be detected as incorrect by the test suite
          (\citealp[p.~5\=/15]{SWEBOK2025}; similar in
          \citealp[pp.~428\==429]{vanVliet2000}) which is not a requirement of
          back-to-back testing.
    \item % Flaw count (WRONG, DEFS): {IEEE2021c} ISTQB {Patton2006} | {Kam2008}
          ``Negative testing'' is defined as ``testing a component or system in
          a way for which it was not intended to be used'' (\citealpISTQB{};
          similar in \citealp[p.~84\==87]{Patton2006}), such as for functionality
          ``not included in the specification'' or ``inputs \dots{} that should
          either be ignored \dots{} or cause \dots{} an error message''
          (\citealp[p.~11]{IEEE2021c}; similar in \citealp[p.~84\==87]{Patton2006}).
          However, \citet[p.~46]{Kam2008}\todo{OG Beizer} says that it is
          ``aimed at showing that a component or system does not work'' which
          misrepresents this approach: yes, it often involves ``testing with
          invalid input values or exceptions'', but these are used to see how a
          component or system handles them, not to prove that it cannot!
    \item % Flaw count (CONTRA, CATS): {SWEBOK2025} | {Kam2008}
          Although ad hoc testing is classified as a ``technique''
          \citep[p.~5\=/14]{SWEBOK2025}, it is one in which ``no recognized test
          design technique is used'' \citep[p.~42]{Kam2008}.
    \item % Flaw count (WRONG, TRACE): {Kam2008}
          % Flaw count (MISS, DEFS): {Kam2008}
          % Label see-ref-missing
          \seeRefMissing{}
    \item % Flaw count (MISS, TRACE): {Kam2008}
          % Assertion: implied by {Lyu1996}
          \citet[p.~42]{Kam2008} cites ``Musa'' as the source of his definition
          of ``operational profile testing'', but this does not appear in his
          references section. Based on \citepos[p.~539]{Lyu1996} discussion of
          similar content, this likely refers to \citep{MusaEtAl1987}.
    \item % Flaw count (WRONG, LABELS): {Kam2008}
          \citet{Kam2008} misspells ``state-based'' as ``state-base''
          \citetext{pp.~13, 15} and ``stated-base'' \citetext{Tab.~1}.
    \item % Flaw count (CONTRA, CATS): {Kam2008} | implied by {IEEE2021c}
          \citet[p.~46]{Kam2008}\todo{OG Beizer} says ``negative testing is
          related to the testers' attitude rather than a specific test approach
          or test design technique''; while \citet{IEEE2021c} seem to support
          this idea of negative testing being at a ``higher'' level than other
          approaches, they also imply that it is a test technique
          \citetext{pp.~10, 14}.
    \item % Flaw count (WRONG, LABELS): {ChalinEtAl2006} | {LahiriEtAl2013}
          % Label stat-assert-check
          \citet[p.~343]{ChalinEtAl2006} list runtime assertion checking and
          static verification as ``two complementary forms of assertion
          checking''; based on how the term ``static assertion checking'' is
          used by \citet[p.~345]{LahiriEtAl2013}, it seems like this should be
          the complement to runtime assertion checking instead.
    \item % Flaw count (REDUN, LABELS): {Gerrard2000a} | {IEEE2022} ISTQB
          The phrase ``continuous automated testing'' \citep[p.~11]{Gerrard2000a}
          is redundant since \acf{ct} is already a subapproach of automated
          testing (\citealp[p.~35]{IEEE2022}; \citealpISTQB{}).
    \item % Flaw count (MISS, DEFS): {Gerrard2000a}
          \citet[Tab.~2]{Gerrard2000a} makes a distinction between
          ``transaction verification'' and ``transaction testing'' and
          uses the phrase ``transaction flows'' \citetext{Fig.~5} but doesn't
          explain them.
    \item % Flaw count (MISS, DEFS): {Gerrard2000a} | {Gerrard2000a}
          % Label gerrard-distinct
          Availability testing is not assigned to a test priority
          \citep[Tab.~2]{Gerrard2000a}, despite the claim that ``the test
          types%\gerrardDistinctIEEE{type}
          \footnote{``Each type of test addresses a different risk area''
              \citep[p.~12]{Gerrard2000a}, which is \distinctIEEE{type}.}
          have been allocated a slot against
          the four test priorities'' \citetext{p.~13}; usability testing and/or
          performance testing would have been good candidates.
    \item % Flaw count (WRONG, DEFS): {Gerrard2000b}
          \citepos[p.~28]{Gerrard2000b} definition of ``manual security audits''
          may be too specific, only applying to ``the products installed on a
          site'' and ``the known vulnerabilities for those products''.
    \item % Flaw count (WRONG, SYNS): {IEEE2017} {SakamotoEtAl2013} | {SneedAndGöschl2000}
          % Label dubious-syns
          \citet[p.~18]{SneedAndGöschl2000}\todo{OG Hetzel88} give
          ``white-box testing'', ``grey-box testing'', and ``black-box testing''
          as synonyms for ``module testing'', ``integration testing'', and
          ``system testing'', respectively, but this mapping is incorrect; for
          example, \citet[p.~444]{IEEE2017} say ``structure-based [(or white-box)]
          testing is not restricted to use at component level and can be used
          at all levels'' and \citet[pp.~345\==346]{SakamotoEtAl2013} describe
          ``black-box integration testing''\todo{more examples?}.
    \item % Flaw count (WRONG, SYNS): {SneedAndGöschl2000}
          % Label dubious-red-box-syn
          \citepos[p.~18]{SneedAndGöschl2000} incorrect claims about test level
          synonyms from \flawref{dubious-syns} make their claim that
          ``red-box testing'' is a synonym for ``acceptance testing'' lose
          credibility.
\end{enumerate}