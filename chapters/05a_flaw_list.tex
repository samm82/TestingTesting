\begin{enumerate}
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021a} {Firesmith2015} | {IEEE2017} {SWEBOK2024} {BarbosaEtAl2006} | {vanVliet2000}
          Regression testing and retesting are sometimes given as two distinct
          approaches (\citealp[p.~8]{IEEE2022}; \citeyear[p.~3]{IEEE2021a};
          \citealp[p.~34]{Firesmith2015}), but sometimes regression testing is
          defined as a form of ``selective retesting'' (\citealp[p.~372]{IEEE2017};
          \citealp[pp.~5\=/8, 6\=/5, 7\=/5 to 7\=/6]{SWEBOK2024};
          \citealp[p.~3]{BarbosaEtAl2006}). Moreover, the two possible variations
          of regression testing given by \citet[p.~411]{vanVliet2000} are
          ``retest-all'' and ``selective retest''\todo{Are these separate
              approaches?}, which is possibly the source
          of the above misconception. This creates a cyclic
          relation between regression testing and selective retesting.
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021c} {IEEE2017} {ISO_IEC2011} | {IEEE2022}
          % Assertion: {Firesmith2015}
          Accessibility testing is a subtype of usability testing
          (\citealp[p.~1]{IEEE2022}; \citeyear[Tab.~A.1]{IEEE2021c};
          \citeyear[p.~6]{IEEE2017}; \citealp{ISO_IEC2011};
          \citealp[p.~58]{Firesmith2015}) but these two test types are listed
          at the same level by \citet[Fig.~2]{IEEE2022}.
    \item % Flaw count (OVER, DEFS): {IEEE2022} | {IEEE2022}
          \citet[p.~34]{IEEE2022} give the
          ``landmark tour'' as an example of ``a tour used for exploratory
          testing'', but they also use the analogy of ``a tour guide lead[ing]
          a tourist through the landmarks of a big city'' to describe tours in
          general. Is the distinction between them the fact that landmark tours
          are pre-planned and follow a decided-upon sequence \citetext{p.~34}?
    \item % Flaw count (WRONG, DEFS): {IEEE2022}
          \citet[p.~5]{IEEE2022} give fuzz testing the tag ``artificial
          intelligence''; while fuzz testing could certainly be implemented in
          this way, it does not seem to be a requirement.
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021b} {IEEE2021c} | ISTQB | {Firesmith2015}
          Integration testing, system testing, and system integration testing
          are all listed as separate test levels (\citealp[p.~12, Fig.~2]{IEEE2022};
          \citeyear[p.~41\==44, 46, 51, 58, 74]{IEEE2021b}; \citeyear[p.~6]{IEEE2021c}),
          but system integration testing is listed as a child of both
          integration testing \citepISTQB{} and system testing
          \citep[p.~23]{Firesmith2015}.
    \item % Flaw count (CONTRA, PARS): ISTQB
          Similarly, the relations between component testing, integration
          testing, and component integration testing are unclear; in particular,
          \citetISTQB{} seem to give integration testing as a parent of component
          integration testing in the latter's definition, but as a child in
          their graph of static and dynamic testing.
    \item % Flaw count (WRONG, LABELS): {IEEE2021c} {SWEBOK2024} {SWEBOK2014}
          % Flaw count (CONTRA, DEFS): {IEEE2021c} | {SWEBOK2024} {SWEBOK2014}
          % Assertion: {IEEE2010} {SWEBOK2024} {vanVliet2000}
          % Label error-guess
          \errorGuessFlaw{}
    \item % Flaw count (WRONG, LABELS): {IEEE2017} {Firesmith2015} {vanVliet2000}
          % Flaw count (WRONG, SYNS): {IEEE2017} {vanVliet2000}
          % Assertion: {IEEE2010} {SWEBOK2024} {vanVliet2000}
          Similarly, ``fault seeding'' is not a synonym of ``error seeding''
          as claimed by \citet[p.~165]{IEEE2017} and
          % TODO: may need to be reordered via \ifnotpaper
          \citet[p.~427]{vanVliet2000}. The term ``error seeding'', also
          used by \citet[p.~34]{Firesmith2015},
          should be abandoned in favour of ``fault seeding'', as it is defined
          as the ``process of intentionally adding known faults to those
          already in a computer program \dots{} [to] estimat[e] the number of
          faults remaining'' \citep[p.~165]{IEEE2017} based on the ratio
          between the number of new faults and the number of introduced faults
          that were discovered \citep[p.~427]{vanVliet2000}.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} {SWEBOK2024} {Firesmith2015} {AmmannAndOffutt2017} {PetersAndPedrycz2000} | {IEEE2022} {Gerrard2000a}
          % Label static-test-flaw 
          ``Software testing'' is often defined to exclude static testing
          (\citealp[p.~13]{Firesmith2015}; \citealp[p.~222]{AmmannAndOffutt2017};
          \citealp[p.~439]{PetersAndPedrycz2000}), restricting ``testing'' to
          mean dynamic validation \citep[p.~5\=/1]{SWEBOK2024} or verification
          ``in which a system or component is executed'' \citep[p.~427]{IEEE2017}.
          However, ``terminology is not uniform among different communities, and
          some use the term `testing' to refer to static techniques%
          \notDefDistinctIEEE{technique} as well'' \citep[p.~5\=/2]{SWEBOK2024}.
          This is done by \citet[pp.~16\==17]{IEEE2022} and
          \citet[pp.~8\==9]{Gerrard2000a}; the former even explicitly
          \emph{exclude} static testing in another
          document \citeyearpar[p.~440]{IEEE2017}!
    \item % Flaw count (CONTRA, CATS): {IEEE2021b} | {IEEE2022}
          When static testing \emph{is} included as part of software testing,
          it is not categorized consistently. \citeauthor{IEEE2021b} categorize
          it as a test level in \citeyearpar[p.~43]{IEEE2021b} but give it its
          own test approach category in \citeyearpar[p.~10, 23, Fig.~2]{IEEE2022}.
    \item % Flaw count (CONTRA, DEFS): {ISO_IEC2023a} | {IEEE2017}
          \citet{ISO_IEC2023a} and \citet[p.~196]{IEEE2017} both say that
          functional suitability is ``concerned with whether the functions meet
          stated and implied needs'', but the former includes ``the functional
          specification'' as part of its scope while the latter explicitly
          excludes it.
    \item % Flaw count (WRONG, SYNS): {ISO_IEC2023a} | ISTQB
          ``Functionality'' is defined as the ``capabilities of the various
          \dots\ features provided by a product'' \citep[p.~196]{IEEE2017}.
          \citetISTQB{} say that it is a synonym of ``functional suitability'',
          which refers to the ``capability of a product to provide [specified]
          functions'' (\citealp{ISO_IEC2023a}; similar in
          \citealp[p.~196]{IEEE2017}; \citealpISTQB{}) as opposed to the
          capabilities of those functions themselves.
          %   It should likely instead be a synonym of its child ``functional
          %   correctness'', which is the ``capability of a product to provide
          %   accurate [and precise] results when used by intended users''
          %   \citep{ISO_IEC2023a}, of ``feature-based testing'' or ``features
          %   testing'', which are mentioned by not defined by \citet[p.~28]{Firesmith2015}
          %   and \citet[Fig.~5]{Gerrard2000a}, respectively, or of ``functions
          %   testing'', which is implied to exist by \citet[Tab.~11]{DoğanEtAl2014}.
    \item % Flaw count (MISS, PARS): {IEEE2021c}
          % Flaw count (MISS, LABELS): {IEEE2021c}
          % Assertion: {Reid1996}
          \citet{IEEE2021c} cite \citet{Reid1996} as the source for their
          Fig.~F.1 but they omit \acf{lcsaj} testing with no explanation, both
          from this figure and from the document as a whole. They label the
          figure as a ``partial ordering'', which might explain its omission
          from Fig.~F.1, but \citet[p.~7]{Reid1996} already identifies that his
          hierarchy is incomplete as ``it relates only a subset of the
          available test completion criteria, so other criteria \dots{} should
          still be considered''.
    \item % Flaw count (REDUN, DEFS): {IEEE2021c} | {IEEE2021c}
          \citet[p.~4]{IEEE2021c} define ``exit point'' as the ``last executable
          statement within a test item'', then later note that it ``is most
          commonly the last executable statement within the test item''.
    \item % Flaw count (CONTRA, SYNS): ISTQB | {BaresiAndPezzè2006}
          A component is an ``entity with discrete structure \dots\ within a
          system considered at a particular level of analysis''
          \citep{ISO_IEC2023b} and ``the terms module, component, and unit
              [sic] are often used interchangeably or defined to be subelements
          of one another in different ways depending upon the context'' with
          no standardized relationship \citep[p.~82]{IEEE2017}. For example,
          \citetISTQB{} define them as synonyms while
          \citet[p.~107]{BaresiAndPezzè2006} say ``components
          differ from classical modules for being re-used in different contexts
          independently of their development''.
          % Flaw count (AMBI, DEFS): {IEEE2017} ISTQB
          Additionally, since components are structurally, functionally, or
          logically discrete \citep[p.~419]{IEEE2017} and ``can be tested in
          isolation'' \citepISTQB{}, ``unit/component/module testing'' could
          refer to the testing of both a module \emph{and} a specific function
          in a module\thesisissueref{14}, introducing a further level of
          ambiguity.
    \item % Flaw count (OVER, SYNS): {IEEE2017} {IEEE2013} | {IEEE2022} {IEEE2017} {Perry2006}
          % Label level-phase-syns
          \citeauthor{IEEE2017} \ifnotpaper
              (\citeyear[pp.~469, 470]{IEEE2017}; \citeyear[p.~9]{IEEE2013}) \else
              \cite[pp.~469, 470]{IEEE2017}, \cite[p.~9]{IEEE2013} \fi say that
          ``test level'' and ``test phase'' are synonyms, both meaning a
          ``specific instantiation of [a] test sub-process'', but they have
          other definitions as well. ``Test level'' can also
          refer to the scope of a test process; for example, ``across the whole
          organization'' or only ``to specific projects''
          \citeyearpar[p.~24]{IEEE2022} and ``test phase'' can also refer to
          the ``period of time in the software life cycle'' when testing occurs
          \citeyearpar[p.~470]{IEEE2017}, usually after the implementation phase
          \citep[pp.~420, 509;][p.~56]{Perry2006}.
    \item % Flaw count (REDUN, PARS): {IEEE2017}
          \citet[p.~375]{IEEE2017} say that ``dependability characteristics
          include availability and its inherent or external influencing
          factors, such as availability''.
    \item % Flaw count (OVER, DEFS): {IEEE2010} | {IEEE2010}
          % Assertion: {SWEBOK2024} {vanVliet2000}
          \citet[p.~128]{IEEE2010} define
          ``error'' as ``a human action that produces an incorrect result'',
          but also as ``an incorrect result'' itself. Since faults are inserted
          when a developer makes an error % \citeyear[pp.~128, 140]{IEEE2010}
          (pp.~128, 140; \citealp[p.~12\=/3]{SWEBOK2024};
          \citealp[pp.~399\==400]{vanVliet2000}), this means that they are
          ``incorrect results'', making ``error'' and ``fault'' synonyms%
          \qtodo{Should we classify this as a Synonym Flaw at all?} and
          the distinction between them less useful.
    \item % Flaw count (OVER, DEFS): {IEEE2010} {SWEBOK2024}
          Additionally, ``error'' can also be defined as ``the
          difference between a computed, observed, or measured value or
          condition and the true, specified, or theoretically correct value
          or condition'' (\citealp[p.~128]{IEEE2010}; similar in
          \citealp[pp.~17\=/18 to 17\=/19, 18\=/7 to 18\=/8]{SWEBOK2024}).
          While this is a widely used definition, particularly in mathematics,
          it makes some test approaches ambiguous.
          % Flaw count (AMBI, DEFS): {IEEE2010} {SWEBOK2024} | {IEEE2010} ISTQB
          For example, back-to-back
          testing is ``testing in which two or more variants of a program are
          executed with the same inputs, the outputs are compared, and errors
          are analyzed in case of discrepancies'' (\citealp[p.~30]{IEEE2010};
          similar in \citealpISTQB{}), which seems to refer to this definition
          of ``error''.
    \item % Flaw count (CONTRA, DEFS): {IEEE2021c} {IEEE2017} | {vanVliet2000} implied by {IEEE2021c}
          % Label c-use-def
          % TODO: SUPP DEFS?
          While a computation data use is defined as the ``use of the value of a
          variable in \emph{any} type of statement'' (\citealp[p.~2]{IEEE2021c};
          \citeyear[p.~83, emphasis added]{IEEE2017}), it is
          often qualified to \emph{not} be a predicate data use
          (\citealp[p.~424]{vanVliet2000}; implied by \citealp[p.~27]{IEEE2021c}).
    \item % Flaw count (CONTRA, DEFS): {IEEE2021c} | {IEEE2017}
          % TODO: SUPP DEFS?
          \citeauthor{IEEE2021c} define an ``extended entry (decision) table''
          both as a decision table where the ``conditions consist of multiple
          values rather than simple Booleans'' \citeyearpar[p.~18]{IEEE2021c}
          and one where ``the conditions and actions are generally described
          but are incomplete'' \citeyearpar[p.~175]{IEEE2017}\todo{OG ISO1984}.
    \item % Flaw count (CONTRA, SYNS): {IEEE2021c} | implied by {IEEE2021c}
          % Flaw count (AMBI, PARS): {IEEE2021c}
          % Assertion: {Reid1996}
          \citet[Fig.~F.1]{IEEE2021c} is an adaptation of
          \citet[Fig.~2]{Reid1996} and one of the changes they make is
          replacing ``branch [coverage]'' with ``branch/decision coverage''.
          \citeauthor{Reid1996} notes that ``the term decision coverage is used
          interchangeably with that of branch coverage'' but that comparing one
          to the other is not a direct mapping (p.~4). \citeauthor{IEEE2021c}
          agree, saying ``branch and decision coverage are closely related%
          \dots{}, although lower levels of coverage may not be the same''
          \citeyearpar[p.~104]{IEEE2021c} and separating the terms in
          (Fig.~G.1, Secs.~5.3.2, 5.3.3, Annex~C.2.2\qtodo{What's the short
              form of ``annex''?}). However, (Fig.~F.1) implies that these
          terms are synonyms, contradicting this separation and making decision
          testing's relations ambiguous.
    \item % Flaw count (WRONG, LABELS): {IEEE2021c}
          A typo in \citep[Fig.~2]{IEEE2021c} means that ``specification-based
          techniques'' is listed twice, when the latter should be
          ``structure-based techniques''.
    \item % Flaw count (REDUN, PARS): {IEEE2017}
          \citet[p.~228]{IEEE2017} provide a definition for ``inspections and
          audits'', despite also giving
          definitions for ``inspection'' \citetext{p.~227} and ``audit''
          \citetext{p.~36}; while the first term \emph{could} be considered a
          superset of the latter two, this distinction doesn't seem useful.
    \item % Flaw count (WRONG, DEFS): {IEEE2017} | {IEEE2017}
          % TODO: SUPP DEFS?
          \citet{IEEE2017} use the same definition for ``partial correctness''
          \citetext{p.~314} and ``total correctness'' \citetext{p.~480}.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} | {IEEE2021c}
          % Assertion: {IEEE2021c} {vanVliet2000} {PetersAndPedrycz2000}
          \citet[p.~83]{IEEE2017}'s definition of
          ``all-\acsp{c-use} testing''---testing that aims to execute all data
          ``use[s] of the value of a variable in any type of statement''---is
          \emph{much} more vague than the definition they give in
          (\citeyear[p.~27]{IEEE2021c}; similar in \citealp[p.~425]{vanVliet2000};
          \citealp[p.~479]{PetersAndPedrycz2000})---testing that exercises
          ``control flow sub-paths from each variable definition to each
          \acs{c-use} of that definition (with no intervening definitions)''.
    \item % Flaw count (CONTRA, CATS): {IEEE2016} | {IEEE2016}
          % Label manual-or-keyword
          Since keyword-driven testing can be used for automated \emph{or}
          manual testing \citep[pp.~4, 6]{IEEE2016}, the claim that ``test
          cases can be either manual test cases or keyword test cases''
          \citetext{p.~6} is incorrect.
    \item % Flaw count (AMBI, DEFS): {IEEE2016} {IEEE2017} {IEEE2012} {vanVliet2000}
          % TODO: SUPP DEFS?
          % Assertion: {WikiHaskell2023}
          ``Data definition'' is defined as a ``statement where a variable is
          assigned a value'' (\citealp[p.~3]{IEEE2021c};
          \citeyear[p.~115]{IEEE2017}; similar in \citeyear[p.~27]{IEEE2012};
          \citealp[p.~424]{vanVliet2000}), but for functional programming
          languages such as Haskell with immutable variables
          \citep{WikiHaskell2023}, this could cause confusion and/or be
          imprecise.
    \item % Flaw count (CONTRA, CATS): {IEEE2022} | implied by {IEEE2022}
          \citet[p.~36]{IEEE2022} say ``A/B testing is not a test
          case generation technique as test inputs are not generated'', where
          ``test case generation technique'' may be a synonym of ``test design
          technique''. However, the inclusion of A/B testing under the heading
          ``Test design and execution'' in the same document implies that it
          may be considered a test technique.\footnote{For simplicity, this
              implied categorization as ``technique'' is omitted from
              \Cref{tab:multiCats}.}
    \item % Flaw count (CONTRA, SYNS): implied by {IEEE2016} | {IEEE2022} {IEEE2016}
          The claim that ``test cases can be either manual test cases or
          keyword test cases'' \citep[p.~6]{IEEE2016} implies that ``keyword-driven
          testing'' could be a synonym of ``automated testing'' instead of its
          child, which seems more reasonable \citeyearpar[p.~4;][p.~35]{IEEE2022}.

          % STD | META
    \item % Flaw count (WRONG, CATS): {IEEE2022} {IEEE2021c} {IEEE2017} | ISTQB
          \citetISTQB{} classify \acs{ml} model testing as a test level, which
          they define as ``a specific instantiation of a test process'': a vague
          definition that does not match the one in \Cref{tab:ieeeCats}.
    \item % Flaw count (CONTRA, PARS): {ISO_IEC2023a} | {Firesmith2015}
          % Label perf-sec-par
          \perfSecParFlaw{}
    \item % Flaw count (CONTRA, PARS): {IEEE2022} {IEEE2021c} {SWEBOK2024} ISTQB | {Firesmith2015}
          Similarly, random testing is a subtechnique of specification-based
          testing (\citealp[pp.~7, 22]{IEEE2022}; \citeyear[pp.~5, 20, Fig.~2]{IEEE2021c};
          \citealp[p.~5\=/12]{SWEBOK2024}; \citealpISTQB{}) but is listed
          separately by \citet[p.~46]{Firesmith2015}.
    \item % Flaw count (OVER, DEFS): {SWEBOK2024} | {IEEE2022}
          The \acs{swebok} V4 defines ``privacy testing'' as testing that
          ``assess[es] the security and privacy of users' personal data to
          prevent local attacks'' \citep[p.~5\=/10]{SWEBOK2024}. This seems to
          overlap (both in scope and name) with the definition of ``security
          testing'' in \citep[p.~7]{IEEE2022}: testing
          ``conducted to evaluate the degree to which a test item, and
          associated data and information, [sic]\qtodo{Shouldn't this be
              ``is'', referring to ``test item''?} are protected so that'' only
          ``authorized persons or systems'' can use them as intended.
    \item % Flaw count (CONTRA, DEFS): {SWEBOK2024} {Patton2006} | {IEEE2017}
          % Label path-test
          Path testing ``aims to execute all entry-to-exit control flow paths
          in a \acs{sut}'s control flow graph'' (\citealp[p.~5\=/13]{SWEBOK2024};
          similar in \citealp[p.~119]{Patton2006}), but \citet[p.~316]{IEEE2017}
          add that it can also be ``designed to execute \dots{} selected paths.''
    \item % Flaw count (CONTRA, DEFS): {IEEE2022} | ISTQB
          % Label tour-def
          % Label tour-def-contra
          \tourFlaw{}
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} | {SWEBOK2024} | ISTQB
          % Label alpha-def
          \alphaFlaw{}
    \item % Flaw count (CONTRA, DEFS): {SWEBOK2024} | {IEEE2017}
          % Assertion: {JardEtAl1999}
          % Flaw count (OVER, DEFS): {SWEBOK2024} | ISTQB {Firesmith2015}
          % Flaw count (AMBI, SYNS): {Kam2008} | ISTQB {Firesmith2015}
          % Flaw count (REDUN, DEFS): {Kam2008}
          ``Conformance testing'' is defined by \citet[p.~5\=/7]{SWEBOK2024} as
          testing that ``aims to verify that the SUT conforms to standards,
          rules, specifications, requirements, design, processes, or practices'',
          but this disagrees with the definition given by the
          \citet[p.~523]{PMBOK2013}: testing that evaluates the degree to which
          ``results \dots{} fall within the limits that define acceptable
          variation for a quality requirement''. \citeauthor{SWEBOK2024}'s
          definition instead seems to correspond to the definition of compliance
          testing given by \citetISTQB{}\todo{OG IREB Glossary} and
          \citet[p.~33]{Firesmith2015}, which may explain why
          \citet[p.~43]{Kam2008} gives them as synonyms (along with his
          unhelpful definition of compliance testing: ``testing to determine
          the compliance of the component or system'').
    \item % Flaw count (AMBI, LABELS): {IEEE2017} | {Firesmith2015} | {Firesmith2015} {Gerrard2000a}
          The distinctions between development testing \citep[p.~136]{IEEE2017},
          developmental testing \citep[p.~30]{Firesmith2015}, and developer
          testing \citep[p.~39;][p.~11]{Gerrard2000a} are unclear and seem
          miniscule.\todo{Is this a def flaw?}
    \item % Flaw count (AMBI, DEFS): ISTQB
          % TODO: SUPP DEFS?
          \citetISTQB{} define
          ``\acf{ml} model testing'' and ``\acs{ml} functional performance''
          in terms of ``\acs{ml} functional performance criteria'',
          which is defined in terms of ``\acs{ml} functional performance
          metrics'', which is defined as ``a set of measures that relate to the
          functional correctness of an \acs{ml} system''. The use
          of ``performance'' (or ``correctness'') in these definitions is at
          best ambiguous and at worst incorrect.
    \item % Flaw count (WRONG, SCOPE): {SWEBOK2024}
          \citet[p.~5\=/4]{SWEBOK2024} says that quality improvement,
          along with quality assurance, is an aspect of testing that involves
          ``defining methods, tools, skills, and practices to achieve the
          specific quality level and objective''; while testing that a system
          possesses certain qualities is in scope, actively improving the
          system in response is \emph{not} part of testing.
    \item % Flaw count (WRONG, TRACE): {SWEBOK2024}
          % Label elas-ref
          \citet[p.~5\=/9]{SWEBOK2024}'s definition of
          ``elasticity testing'' \swebokElasRef{}
    \item % Flaw count (CONTRA, SYNS): ISTQB implied by {IEEE2015} | {SWEBOK2024}
          % Assertion: implied by {Gerrard2000a}
          % Label stage-level-syns
          The terms ``test level'' and ``test stage'' are given as synonyms
          (\citealpISTQB{}; implied by \citealp[p.~9]{IEEE2015};
          \citealp[p.~9]{Gerrard2000a}), but
          \citet[p.~5\=/6]{SWEBOK2024} says ``[test] levels can be distinguished
          based on the object of testing, the \emph{target}, or on the purpose
          or \emph{objective}'' and calls the former ``test stages'', giving
          the term a child relation (see \Cref{par-chd-rels}) to ``test level''
          instead. However, the examples of ``test stages'' listed---unit
          testing, integration testing, system testing, and acceptance testing
          \citep[pp.~5\=/6 to 5\=/7]{SWEBOK2024}---are commonly categorized as
          ``test levels'' (see \Cref{cats-def}).
    \item % Flaw count (WRONG, SCOPE): {Firesmith2015}
          % Assertion: {LiuEtAl2023} {MorgunEtAl1999} {HolleyEtAl1996} {HoweAndJohnson1995}
          % Label assert-truth
          \tolTestFlaw{}
    \item % Flaw count (OVER, LABELS): {SWEBOK2024} implied by {Valcheva2013} {YuEtAl2011} | {Firesmith2015}
          ``Orthogonal array testing'' (\citealp[pp.~5\=/1, 5\=/11]{SWEBOK2024};
          implied by \citealp[pp.~467, 473]{Valcheva2013};
          \citealp[pp.~1573\==1577, 1580]{YuEtAl2011}) and ``operational
          acceptance testing'' \citep[p.~30]{Firesmith2015} have the same
          acronym (``OAT'').
    \item % Flaw count (CONTRA, SYNS): ISTQB | {Firesmith2015}
          % Label oat-pat-syns
          ``Operational acceptance testing'' and ``production acceptance
          testing'' are given as synonyms by \citetISTQB{} but listed
          separately by \citet[p.~30]{Firesmith2015}.
    \item % Flaw count (AMBI, DEFS): {SWEBOK2024} | {SWEBOK2024}
          % Assertion: {vanVliet2000}
          While ``error'' is defined as ``a human action that produces an
          incorrect result'' (\citealp[pp.~12\=/3]{SWEBOK2024}\todo{OG [14]};
          \citealp[p.~399]{vanVliet2000}), \citeauthor{SWEBOK2024} does not
          use this consistently, sometimes implying that errors can be instrinsic
          to software itself \citeyearpar[pp.~4\=/9, 6\=/5, 7\=/3, 12\=/4,
              12\=/9, 12\=/13]{SWEBOK2024}.\qtodo{I ignore ``syntax errors,
              runtime errors, and logical errors'' \citep[p.~16\=/13,
                  cf.~p.~18\=/13]{SWEBOK2024} since they seem to be in different
              domains. Does that make sense? How should I document this?}
    \item % Flaw count (AMBI, LABELS): {IEEE2019a} {IEEE2010} | {SWEBOK2024}
          % Assertion: {vanVliet2000}
          \refHelper{} \citet[p.~1\=/1]{SWEBOK2024} defines ``defect'' as ``an
          observable difference between what the software is intended to do and
          what it does'', but this seems to match the definition of
          ``failure'': the inability of a system ``to perform a required
          function or \dots{} within previously specified limits''
          (\citealp[p.~7]{IEEE2019a}; \citeyear[p.~139]{IEEE2010}%
          \todo{OG ISO/IEC, 2005}; similar in \citealp[p.~400]{vanVliet2000})
          that is ``externally visible'' (\citealp[p.~7]{IEEE2019a}; similar in
          \citealp[p.~400]{vanVliet2000}).
    \item % Flaw count (AMBI, LABELS): {SWEBOK2024} | {SWEBOK2024}
          % Assertion: {vanVliet2000}
          Similarly, \citet[p.~4\=/11]{SWEBOK2024} says ``fault tolerance is
          a collection of techniques that increase software reliability by
          detecting errors and then recovering from them or containing their
          effects if recovery is not possible.'' This should either be called
          ``\emph{error} tolerance'' or be described as ``detecting
          \emph{faults} and then recovering from them'', since ``error'' and
          ``fault'' have distinct meanings (\citealp[p.~5\=/3]{SWEBOK2024};
          \citealp[pp.~399\==400]{vanVliet2000}). The intent of this
          term-definition pair is unclear, as the strategies given---``backing
          up and retrying, using auxiliary code and voting algorithms, and
          replacing an erroneous value with a phony value that will have a
          benign effect'' \citep[p.~4\=/11]{SWEBOK2024}---could be used for
          errors or faults.
    \item % Flaw count (REDUN, LABELS): {SWEBOK2024}
          % Assertion: {Gerrard2000b}
          % Label ethical-hacking
          ``Ethical hacking testing'' is given as a synonym of penetration
          testing by \citet[p.~13\=/4]{SWEBOK2024}, which seems redundant;
          \citet[p.~28]{Gerrard2000b} uses the term ``ethical hacking'' which
          is clearer.
    \item % Flaw count (CONTRA, CATS): {IEEE2022} {IEEE2021a} {IEEE2021b} | ISTQB
          % Flaw count (CONTRA, CATS): {IEEE2022} {IEEE2021a} {IEEE2021b} | {BarbosaEtAl2006}
          % Don't double count "ISTQB | {BarbosaEtAl2006}" multiCat flaw
          % Flaw count (AMBI, CATS): {IEEE2022} {IEEE2021c} {IEEE2017} {SWEBOK2024} ISTQB {KuļešovsEtAl2013} {Perry2006} {PetersAndPedrycz2000} {Gerrard2000a} | {BarbosaEtAl2006}
          % Flaw count (AMBI, CATS): {IEEE2022} {IEEE2021c} {IEEE2017} | {IEEE2022} {IEEE2021a} {IEEE2021b}
          % Assertion: {SWEBOK2024} ISTQB {KuļešovsEtAl2013} {Perry2006} {PetersAndPedrycz2000} {Gerrard2000a}
          Retesting and regression testing seem to be categorized separately
          from the rest of the testing approaches (\citealp[pp.~15, 23]{IEEE2022};
          \citeyear[p.~8]{IEEE2021a}; \citeyear[p.~4]{IEEE2021b}) but this is
          not justified. \citetISTQB{} consider regression testing to be a test
          type and \citet[p.~3]{BarbosaEtAl2006} consider it a test level;
          since it is not included as an example of a test level by the sources
          that describe them (see \Cref{cats-def}), this latter categorization
          is likely not universal at best and incorrect at worst.
    \item % Flaw count (AMBI, DEFS): ISTQB
          While ergonomics testing is out of scope (as it tests hardware, not
          software; see \Cref{hard-test}), its definition of ``testing to
          determine whether a component or system and its input devices are
          being used properly with correct posture'' \citepISTQB{} seems to
          focus on how the system is \emph{used} as opposed to the system
          \emph{itself}.
    \item % Flaw count (AMBI, DEFS): ISTQB
          Similarly, end-to-end testing is defined as testing ``in which
          business processes are tested from start to finish under
          production-like circumstances'' \citepISTQB{}; it is unclear
          whether this tests the business processes themselves or the system's
          role in performing them.
    \item % Flaw count (AMBI, DEFS): ISTQB
          % Flaw count (AMBI, TRACE): ISTQB
          % Assertion: {SPICE2022}
          \citetISTQB{} describe the term ``software in the loop'' as a kind of
          testing, while the source they reference seems to
          describe ``Software-in-the-Loop-Simulation'' as a ``simulation
          environment'' that may support software integration testing
          \citep[p.~153]{SPICE2022}; is this a testing approach or a tool
          that supports testing?
    \item % Flaw count (WRONG, SCOPE): ISTQB
          % Label specific-istqb
          The definition of ``math testing'' given by \citetISTQB{} is
          too specific to be useful, likely taken from an example instead of
          a general definition: ``testing to determine the correctness of the
          pay table implementation, the random number generator results, and
          the return to player computations''.
    \item % Flaw count (WRONG, SCOPE): ISTQB
          A similar issue exists with multiplayer testing, where its
          definition specifies ``the casino game world'' \citepISTQB{}.
    \item % Flaw count (REDUN, DEFS): ISTQB
          While correct, ISTQB's definition of ``specification-based testing''
          is not helpful: ``testing based on an analysis of the specification
          of the component or system'' \citepISTQB{}.
    \item % Flaw count (WRONG, SCOPE): ISTQB
          % Assertion: {Bluejay2024}
          % Label par-sheet-test
          \parSheetTestFlaw{}
    \item % Flaw count (WRONG, TRACE): ISTQB
          The source that \citetISTQB{} cite for the definition of ``test
          type'' does not seem to actually provide a definition.
    \item % Flaw count (WRONG, TRACE): ISTQB
          The same is true for ``visual testing'' \citepISTQB{}.
    \item % Flaw count (WRONG, TRACE): ISTQB
          The same is true for ``security attack'' \citepISTQB{}.
    \item % Flaw count (WRONG, SYNS): ISTQB
          % Assertion: {Reid1996}
          \citet[p.~4]{Reid1996} says ``the use of the term `condition' in
          branch condition testing can mislead the reader into thinking all
          conditions are exercised'', which \citetISTQB{} seem to do by giving
          ``condition coverage'' as a synonym of ``branch condition coverage''.
    \item % Flaw count (AMBI, DEFS): {Firesmith2015} | {Firesmith2015}
          While model testing is said to test the object under test,
          it seems to describe testing the models themselves
          \citep[p.~20]{Firesmith2015}; using the models to test the object
          under test seems to be called ``driver-based testing''
          \citetext{p.~33}.
    \item % Flaw count (AMBI, DEFS): {Firesmith2015}
          Similarly, it is ambiguous whether ``tool/environment testing'' refers
          to testing the tools/environment \emph{themselves} or \emph{using}
          them to test the object under test; the wording of its subtypes
          \citep[p.~25]{Firesmith2015} seems to imply the former.
    \item % Flaw count (MISS, DEFS): {Firesmith2015}
          The acronym for \acf{sos} \citep{IEEE2019b} is used but not defined
          by \citet[p.~23]{Firesmith2015}.
    \item % Flaw count (OVER, LABELS): {Firesmith2015} | {Firesmith2015}
          % Label cat-acro
          ``Customer acceptance testing'' and ``contract(ual) acceptance
          testing'' have the same acronym (``CAT'') \citep[p.~30]{Firesmith2015}.
    \item % Flaw count (OVER, LABELS): {Firesmith2015} | {Firesmith2015}
          % Label hil-acro
          The same is true for ``hardware-in-the-loop testing'' and
          ``human-in-the-loop testing'' (``HIL'') \citep[p.~23]{Firesmith2015},
          % Flaw count (CONTRA, LABELS): {Firesmith2015} | {PreußeEtAl2012}
          although \citet[p.~2]{PreußeEtAl2012} use ``HiL'' for the former.
    \item % Flaw count (WRONG, TRACE): {DoğanEtAl2014}
          \citet[p.~184]{DoğanEtAl2014} claim that \citet{SakamotoEtAl2013}
          define ``prime path coverage'', but they do not.
    \item % Flaw count (AMBI, PARS): {PMBOK2013} | {PMBOK2013}
          The \citet[p.~244; similar on p.~535]{PMBOK2013} says ``quality
          assurance work will fall under the conformance work category in the
          cost of quality framework'', but (Fig.~8\=/2) suggests that
          ``conformance work'' is a part of quality assurance. This
          introduces ambiguity at best and creates a cyclic parent-child
          relation (which violates our definition in \Cref{par-chd-rels}%
          \qtodo{Should I be more specific?}) at worst.
    \item % Flaw count (MISS, LABELS): {PMBOK2013}
          The \citet[p.~476]{PMBOK2013} uses the acronym ``QA'' which is
          implied to refer to ``quality assurance'' as ``QC'' refers to
          ``quality control'' (p.~535), but this is not made explicit.

          % META | TEXT
    \item % Flaw count (WRONG, TRACE): {PetersAndPedrycz2000} | {PetersAndPedrycz2000}
          % Label myers-citation
          \citet[pp.~438, 497]{PetersAndPedrycz2000} cite \citet{Myers1976}
          but misspell the author's name as ``Meyers'' in the References
          section of the relevant chapter (p.~500). This is especially
          confusing since they also include \citet{Myers1992} in the
          bibliography, which was written by a different author.
    \item % Flaw count (CONTRA, PARS): implied by {Patton2006} | {vanVliet2000}
          While \citet[p.~120]{Patton2006} implies that condition testing is a
          subtechnique of path testing, \citet[Fig.~13.17]{vanVliet2000} says
          that multiple condition coverage (which seems to be a synonym of
          condition coverage \citetext{p.~422}) does not subsume and is not
          subsumed by path coverage.
    \item % Flaw count (WRONG, SYNS): {IEEE2010} {SWEBOK2024} {vanVliet2000} | {Patton2006}
          % Label bug-patton
          The differences between the terms ``error'', ``failure'',
          ``fault'', ``defect'' are significant and meaningful
          (\citealp[pp.~128, 139\==140]{IEEE2010}; \citealp[p.~12\=/3]{SWEBOK2024};
          \citealp[pp.~399\==400]{vanVliet2000}), but \bugPattonFlaw{}
    \item % Flaw count (CONTRA, DEFS): {IEEE2022} | {Patton2006}
          % Label load-def
          \loadFlaw{}
    \item % Flaw count (CONTRA, DEFS): {IEEE2021c} | {Patton2006}
          State testing requires that ``all states in the state model
          \dots\ [are] `visited'\,'' \citep[p.~19]{IEEE2021c}, but
          \citet[pp.~82\==83]{Patton2006} lists this as only one of its
          possible criteria.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} {PetersAndPedrycz2000} {vanVliet2000} | {Patton2006}
          System testing is ``conducted on a complete, integrated system''
          (\citealp[p.~456]{IEEE2017}; similar in \citealp[Tab.~12.3]{PetersAndPedrycz2000};
          \citealp[p.~439]{vanVliet2000}), but \citet[p.~109]{Patton2006}
          says it can also be done on ``at least a major portion'' of the product.
    \item % Flaw count (AMBI, SYNS): ISTQB | {Patton2006}
          % TODO: NEAR SYNS?
          \citetISTQB{} claim that code inspections are related to peer reviews
          but \citet[pp.~94\==95]{Patton2006} makes them quite distinct.
    \item % Flaw count (AMBI, PARS): {IEEE2017} | {Patton2006} implied by {IEEE2021c} {vanVliet2000}
          \citet[p.~119]{Patton2006} says that branch testing is ``the simplest
          form of path testing'' which is also implied by
          \citet[Fig.~F.1]{IEEE2021c} and
          \citet[p.~433]{vanVliet2000}. This is true in the example
          \citeauthor{Patton2006} gives, but is not necessarily generalizable;
          one could test the behaviour at branches without testing even a
          \emph{subset} of complete paths, which \citet[p.~316]{IEEE2017} give
          as a definition of ``path testing'' (see \flawref{path-test})!
    \item % Flaw count (CONTRA, SYNS): ISTQB | {PetersAndPedrycz2000}
          % Label walkthrough-syns
          ``Walkthroughs'' and ``structured walkthroughs'' are given
          as synonyms by \citetISTQB{} but \citet[p.~484]{PetersAndPedrycz2000}
          imply that they are different, saying a
          more structured walkthrough may have specific roles.
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | implied by {Patton2006}
          While \citet[p.~92\ifnotpaper, emphasis added\fi]{Patton2006}
          says that reviews are ``\emph{the} process[es] under which static
          white-box testing is performed'', \citet[pp.~418\==419]{vanVliet2000}
          gives correctness proofs as another example.
    \item % Flaw count (CONTRA, LABELS): {IEEE2021c} {IEEE2017} {PetersAndPedrycz2000} {Reid1996} | {vanVliet2000}
          % TODO: SUPP LABELS?
          Different capitalizations of the abbreviations of ``computation data
          use'' and ``predicate data use'' are used: the lowercase ``\acs{c-use}''
          and ``\acs{p-use}'' (\citealp[pp.~3, 27\==29, 35\==36, 114\==155,
              117\==118, 129]{IEEE2021c}; \citeyear[p.~124]{IEEE2017};
          \citealp[p.~477, Tab.~12.6]{PetersAndPedrycz2000};
          \citealp[Fig.~2]{Reid1996}) and the uppercase ``C-use'' and ``P-use''
          \citep[pp.~424\==425]{vanVliet2000}.
    \item % Flaw count (CONTRA, LABELS): {IEEE2021c} {PetersAndPedrycz2000} {Reid1996} | {vanVliet2000}
          % TODO: SUPP LABELS?
          Similarly for ``definition-use'' (such as in ``definition-use
          path''), both the lowercase ``du'' (\citealp[pp.~3, 27, 29, 35,
              119\==121, 129]{IEEE2021c}; \citealp[pp.~478\==479]{
              PetersAndPedrycz2000}; \citealp[Fig.~2]{Reid1996}) and the
          uppercase ``DU'' \citep[p.~425]{vanVliet2000} are used.
    \item % Flaw count (MISS, DEFS): {IEEE2021c} {IEEE2017} {PetersAndPedrycz2000} implied by {vanVliet2000} | {vanVliet2000}
          \Citet[p.~425]{vanVliet2000} defines many types of data
          flow coverage, including all-\acsp{p-use},
          all-\acsp{p-use}/some-\acsp{c-use}, and
          all-\acsp{c-use}/some-\acsp{p-use}, but
          excludes all-\acsp{c-use}, which is implied by these definitions and
          defined elsewhere (\citealp[p.~27]{IEEE2021c};
          \citeyear[p.~83]{IEEE2017}; \citealp[p.~479]{PetersAndPedrycz2000}).
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | {IEEE2021c} {IEEE2017} {PetersAndPedrycz2000}
          \Citet[pp.~424\==425]{vanVliet2000} specifies that every
          successor of a data definition use needs to be executed as part of
          all-uses testing, but this condition is not included elsewhere
          (\citealp[pp.~28\==29]{IEEE2021c}; \citeyear[p.~120]{IEEE2017};
          \citealp[pp.~478\==479]{PetersAndPedrycz2000}).
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | {IEEE2021c} {IEEE2017} {SWEBOK2024} {PetersAndPedrycz2000}
          All-\acsp{du-path} testing is usually defined as exercising all
          ``loop-free control flow sub-paths from each variable definition to
          every use (both \acs{p-use} and \acs{c-use}) of that definition (with no
          intervening definitions)'' (\citealp[p.~29]{IEEE2021c}; similar in
          \citeyear[p.~125]{IEEE2017}; \citealp[p.~5\=/13]{SWEBOK2024};
          \citealp[p.~479]{PetersAndPedrycz2000}); however, paths containing
          simple cycles may also be required \citep[p.~425]{vanVliet2000}.
          % This was only a flaw when looking at IEEE2021c
          % \item % OUTDATED Flaw count (CONTRA, DEFS): {vanVliet2000} | implied by {Reid1996}
          %       \Citet[pp.~432\==433]{vanVliet2000} says that all-\acsp{p-use}
          %       testing is only stronger than all-edges (branch) testing if there are
          %       infeasible paths, but \citet[pp.~3, 6\==7]{Reid1996} only specifies
          %       this caveat implicitly.
    \item % Flaw count (CONTRA, DEFS): {vanVliet2000} | {SWEBOK2024}
          Similarly, \citet[pp.~432\==433]{vanVliet2000} says that
          all-\acsp{du-path} testing is only stronger than all-uses testing if
          there are infeasible paths, but \citet[p.~5\=/13]{SWEBOK2024} does
          not specify this caveat.
    \item % Flaw count (WRONG, PARS): {IEEE2021c} {IEEE2017} {vanVliet2000} | implied by {PetersAndPedrycz2000}
          \citet[Fig.~12.31]{PetersAndPedrycz2000} \ifnotpaper imply
          \else implies \fi that decision coverage is a child of both \acs{c-use}
          coverage \emph{and} \acs{p-use} coverage; this seems incorrect, since
          decisions are the result of \acsp{p-use} and \emph{not} \acsp{c-use}
          (\citealp[pp.~5, 27]{IEEE2021c}; \citeyear[p.~332]{IEEE2017};
          \citealp[p.~424]{vanVliet2000}), and only the \acs{p-use} relation is
          implied by \citet[Fig.~F.1]{IEEE2021c}.
    \item % Flaw count (CONTRA, DEFS): {IEEE2017} | {SWEBOK2014} | {vanVliet2000}
          Acceptance testing is ``usually performed by the purchaser \dots{}
          with the \dots{} vendor'' \citep[p.~5]{IEEE2017}, ``may or may not
          involve the developers of the system'' \citep[p.~4\=/6]{SWEBOK2014},
          and/or ``is often performed under supervision of the user
          organization'' \citep[p.~439]{vanVliet2000}; these descriptions
          of who the testers are contradict each other \emph{and} all introduce
          some uncertainty\qtodo{Does this merit counting this as an Ambiguity
              as well as a Contradiction?}
          (``usually'', ``may or may not'', and ``often'', respectively).

          % TEXT | PAPER
    \item % Flaw count (MISS, DEFS): {Bas2024}
          \citet[p.~16]{Bas2024} lists ``three [backup] location
          categories: local, offsite and cloud based [sic]'' but does not
          define or discuss ``offsite backups'' \citetext{pp.~16\==17}.
    \item % Flaw count (WRONG, SYNS): implied by {SharmaEtAl2021}
          \citet[p.~601]{SharmaEtAl2021} seem to use the terms ``grey-box
          testing'' and ``(stepwise) code reading'' interchangeably, which would
          incorrectly imply that they are synonyms\todo{FIND SOURCES}.
    \item % Flaw count (WRONG, SYNS): {IEEE2017} ISTQB {PetersAndPedrycz2000} {vanVliet2000} {SakamotoEtAl2013} | {Kam2008}
          \citet[p.~46]{Kam2008} gives ``program testing'' as a synonym of
          ``component testing'' but it would make more sense as a synonym of
          ``system testing'', which is conducted on the system, or program, as
          a whole (\citealp[p.~456\todo{OG 2012}]{IEEE2017}; \citealpISTQB{};
          \citealp[Tab.~12.3]{PetersAndPedrycz2000}; \citealp[p.~439]{vanVliet2000};
          \citealp[pp.~343\==344]{SakamotoEtAl2013}).
    \item % Flaw count (WRONG, SYNS): {SWEBOK2024} {vanVliet2000} | {Kam2008}
          \citet[p.~46]{Kam2008} gives ``mutation testing'' as a
          synonym of ``back-to-back testing''; while the two are related
          \citep[p.~30]{IEEE2010}, the variants used in mutation testing are
          generated or designed to be detected as incorrect by the test suite
          (\citealp[p.~5\=/15]{SWEBOK2024}; similar in
          \citealp[pp.~428\==429]{vanVliet2000}) which is not a requirement of
          back-to-back testing.
    \item % Flaw count (WRONG, DEFS): ISTQB | {Kam2008}
          \citet[p.~46]{Kam2008}\todo{OG Beizer} says that the goal
          of negative testing is ``showing that a component or system does not
          work'' which is not true; if robustness is an important quality for
          the system, then testing the system ``in a way for which it was not
          intended to be used'' \citepISTQB{} (i.e., negative testing) is one
          way to help test this!
    \item % Flaw count (CONTRA, CATS): {SWEBOK2024} | {Kam2008}
          Although ad hoc testing is classified as a ``technique''
          \citep[p.~5\=/14]{SWEBOK2024}, it is one in which ``no recognized test
          design technique is used'' \citep[p.~42]{Kam2008}.
    \item % Flaw count (WRONG, TRACE): {Kam2008}
          % Flaw count (MISS, DEFS): {Kam2008}
          % Label see-ref-missing
          \seeRefMissing{}
    \item % Flaw count (WRONG, LABELS): {Kam2008}
          \citet{Kam2008} misspells ``state-based'' as ``state-base''
          \citetext{pp.~13, 15} and ``stated-base'' \citetext{Tab.~1}.
    \item % Flaw count (CONTRA, CATS): {Kam2008} | implied by {IEEE2021c}
          \citet[p.~46]{Kam2008}\todo{OG Beizer} says ``negative testing is
          related to the testers' attitude rather than a specific test approach
          or test design technique''; while \citet{IEEE2021c} seem to support
          this idea of negative testing being at a ``higher'' level than other
          approaches, they also imply that it is a test technique
          \citetext{pp.~10, 14}.
    \item % Flaw count (REDUN, LABELS): {Gerrard2000a} | {IEEE2022} ISTQB
          The phrase ``continuous automated testing'' \citep[p.~11]{Gerrard2000a}
          is redundant since \acf{ct} is already a subapproach of automated
          testing (\citealp[p.~35]{IEEE2022}; \citealpISTQB{}).
    \item % Flaw count (MISS, DEFS): {Gerrard2000a}
          \citet[Tab.~2]{Gerrard2000a} makes a distinction between
          ``transaction verification'' and ``transaction testing'' and
          uses the phrase ``transaction flows'' \citetext{Fig.~5} but doesn't
          explain them.
    \item % Flaw count (MISS, DEFS): {Gerrard2000a} | {Gerrard2000a}
          % Label gerrard-distinct
          Availability testing is not assigned to a test priority
          \citep[Tab.~2]{Gerrard2000a}, despite the claim that ``the test
          types%\gerrardDistinctIEEE{type}
          \footnote{``Each type of test addresses a different risk area''
              \citep[p.~12]{Gerrard2000a}, which is \distinctIEEE{type}}
          have been allocated a slot against
          the four test priorities'' \citetext{p.~13}; usability testing and/or
          performance testing would have been good candidates.
    \item % Flaw count (WRONG, DEFS): {Gerrard2000b}
          \citet[p.~28]{Gerrard2000b}'s definition of ``manual security audits''
          may be too specific, only applying to ``the products installed on a
          site'' and ``the known vulnerabilities for those products''.
    \item % Flaw count (WRONG, SYNS): {IEEE2017} {SakamotoEtAl2013} | {SneedAndGöschl2000}
          % Label dubious-syns
          \citet[p.~18]{SneedAndGöschl2000}\todo{OG Hetzel88} give
          ``white-box testing'', ``grey-box testing'', and ``black-box testing''
          as synonyms for ``module testing'', ``integration testing'', and
          ``system testing'', respectively, but this mapping is incorrect; for
          example, \citet[p.~444]{IEEE2017} say ``structure-based [(or white-box)]
          testing is not restricted to use at component level and can be used
          at all levels'' and \citet[pp.~345\==346]{SakamotoEtAl2013} describe
          ``black-box integration testing''\todo{more examples?}.
    \item % Flaw count (WRONG, SYNS): {SneedAndGöschl2000}
          % Label dubious-red-box-syn
          The previous flaw makes the claim that
          ``red-box testing'' is a synonym for ``acceptance testing''
          \citep[p.~18]{SneedAndGöschl2000} lose credibility.
\end{enumerate}