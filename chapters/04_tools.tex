\ifnotpaper
    \section{Tools}
\else
    \subsection{Tools}
\fi
\label{tools}

\ifnotpaper
    To better understand our findings, we build tools to more intuitively
    visualize relations between test approaches (\Cref{graph-gen}) and
    automatically track their flaws (\Cref{flaw-analysis}). Doing
    this manually would be error-prone due to the amount of data involved (for
    example, we identify \approachCount{} test approaches) and the number of
    situations where the underlying data would change, including more detailed
    analysis, error corrections, and the addition of data. These all require
    tedious updates to the corresponding graphs that may be overlooked or done
    incorrectly. Besides being more systematic, automating these processes also
    allows us to observe the impacts of smaller changes, such as unexpected
    flaws that arise from a new relation between two approaches. It
    also helps verify the tools themselves; for example, tracking a flaw
    manually should affect relevant flaw counts, which we can double-check.
    We also define macros to help achieve our goals of
    maintainability, traceability, and reproducibility (\Cref{macros}).

    \subsection{Approach Graph Generation}
    \label{graph-gen}
\fi

To better visualize how test approaches relate to each other, we
develop a tool to automatically generate graphs of these relations.
\ifnotpaper Since synonym (see \Cref{syn-rels}) and parent-child relations
    (see \Cref{par-chd-rels}) between approaches are tracked in
    \ourApproachGlossary{} in a consistent format, we can parse them
    systematically. For example, if the entries in \Cref{tab:exampleGlossary}
    appear in the glossary, then their parent relations are displayed as
    \Cref{fig:exampleGraph} in the generated graph. Relevant citation
    information is also captured in our glossary following the author-year
    citation format, including ``reusing'' information from previous
    citations. For example, the first row of \Cref{tab:exampleGlossary}
    contains the citation ``(Author, 0000; 0001)'', which means that this
    information was present in two documents by ``Author'': one written in
    the year 0000, and one in 0001. The following citation, ``(0000)'',
    contains no author, which means it was written by the same one as the
    previous citation (Author). These citations are processed according to this
    logic \seeSrcCode{82167b7}{scripts/csvToGraph.py}{55}{96} so they can be
    consistently tracked throughout the analysis.

    \input{build/exampleGlossary.tex}

    \ExampleGraph{}

    \newpage\fi
We graph all parent-child relations, since they are guaranteed to be visually
meaningful, but only graph some synonym relations. For a given synonym pair to
be captured by our methodology, at least one term will have its own row in its
relevant glossary. We then decide whether to include or exclude the synonym
pair from our generated graphs based on the following possible cases:
\begin{description}
    \item[1. (Excluded)] \phantomsection{}\label{case-one}
          \ifnotpaper\else \hfill\break \fi
          \textbf{Only one synonym has its own row.}
          This is a ``typical'' synonym relation (see \Cref{syn-rels}) where
          the terms are interchangeable. We \emph{could} include the synonym
          as an alternate name inside the node of its partner, but we do not
          want to clutter our graphs unnecessarily.

          % Reference for singular 'row': https://ell.stackexchange.com/q/105868/169502
    \item[2. (Included)] \phantomsection{}\label{case-two}
          \ifnotpaper\else \hfill\break \fi
          \textbf{Both synonyms have their own row in the glossary.}
          This may indicate that the synonym relation is incorrect, as it
          equates separate approaches (with their own definitions, nuances,
          etc.) that should likely be distinct. This could, however, also
          indicate that the two terms are interchangeable and could be merged
          % TODO: pretty hacky
          into one row, which would result in \hyperref[case-one]{Case 1} above.

    \item[3. (Included)] \phantomsection{}\label{case-three}
          \ifnotpaper\else\hfill\break\fi
          \textbf{Two synonym pairs share a synonym without its own row.}
          This is a transitive extension to the previous case. If
          two distinct approaches share a synonym, that implies that they are
          synonyms themselves, resulting in the same possibility of the
          relation being incorrect.\qtodo{Is this clear enough?}
\end{description}
\ifnotpaper
    \input{build/synExampleGlossary.tex}
    We deduce these conditions from the information we parse from our
    glossary. For example, if the entries in \Cref{tab:synExampleGlossary}
    appear in the glossary, then they are displayed as \Cref{fig:synExampleGraph}
    in the generated graph (note that X does not appear since it does not
    meet any of the criteria given above).

    Since we can detect these conditions automatically, the next logical step
    is to automatically detect related classes of flaws. The most trivial class
    to automate is that of ``multi-synonym'' relations
    % TODO: pretty hacky
    (\hyperref[case-three]{Case 3} above) since we already find these to
    generate our graphs. We automatically generate the list in \Cref{multiSyns}
    based on glossary entries such as those found in
    \Cref{tab:synExampleGlossary}. The self-referential definitions in
    \Cref{selfPars} are also trivial to automate by looking for lines in the
    generated \LaTeX{} files that start with \texttt{I -> I}, where \texttt{I}
    is the label used for a test approach node in these graphs. This process
    results in output similar to \Cref{fig:selfExampleGraph}. We use a similar
    process to detect pairs of approaches with a synonym relation \emph{and} a
    parent-child relation. To accomplish this, we build a dictionary of each
    term's synonyms to evaluate which synonym relations are notable enough to
    include in the graph, and then check these mappings to see if one appears
    as a parent of the other. For example, if \texttt{J} and \texttt{K} are
    synonyms, a generated \LaTeX{} file with a parent line starting with
    \texttt{J -> K} would result in these approaches being graphed as shown in
    \Cref{fig:parSynExampleGraph}.

    \phantomsection{}\label{expAndImp}
    The visual nature of these graphs means we can represent explicit
    \emph{and} implicit relations without double counting them during the
    analysis in \Cref{flaw-analysis}. If a relation is both explicit
    \emph{and} implicit, we only include the implicit relation in the graph
    if it is from a more ``trusted'' source tier (see \Cref{sources}).
    For example, note that only the explicit synonym relation between E and F
    from \Cref{tab:exampleGlossary} appears in \Cref{fig:synExampleGraph}.
    Implicit approaches and relations are denoted by dashed lines, as shown
    in \Cref{fig:exampleGraph,fig:synExampleGraph}; explicit approaches are
    \emph{always} denoted by solid lines, even if they are also implicit.
    We can also generate ``rigid'' versions of these graphs that exclude
    implicit approaches and relations; for example,
    \Cref{fig:rigidExampleGraph} is the rigid version \Cref{fig:exampleGraph}.

\fi
Since these graphs tend to be large, it is useful to focus on specific
subsets of them. \ifnotpaper For each approach category (see
    \Cref{categories-observ}), we generate a graph restricted to its approaches
    and the relations between them. We also generate a graph of all static
    approaches along with the relations between them \emph{and} between a
    static approach and a dynamic approach. We generate this static-focused
    graph because static testing is sometimes considered to be a separate
    approach category \citep[Fig.~2; see \Cref{static-test}]{IEEE2022},
    but we include the relations with dynamic approaches since they are our
    primary focus. We color all dynamic approach nodes in these graphs grey,
    as in \Cref{fig:staticExampleGraph}, to distinguish them.

    We can also generate more specific subsets of these graphs
\else We can generate more focused graphs \fi from a given subset of
approaches, such as \ifnotpaper\else those in a selected approach category
    (see \Cref{categories-observ}) or \fi those pertaining to recovery or
scability\ifnotpaper. These areas are of particular note as we give them their
own sections for discussing flaws (\Cref{recov-flaw,scal-flaw}, respectively).
We generate graphs of just these subsets of software testing to help visualize
the relations between these approaches, given\else; the latter are shown \fi
in \Cref{fig:recovery-graph-current,fig:scal-graph-current}, respectively. By
specifying sets of approaches and relations to add or remove, we can then
update these generated graphs based on our recommendations; applying those
given in \Cref{rec-test-rec,,scal-test-rec,,\ifnotpaper\else perf-test-rec\fi}
results in the updated graphs in \Cref{fig:recovery-graph-proposed,,%
    fig:scal-graph-proposed,,\ifnotpaper\else fig:perf-graph\fi}, respectively.
We color any added approaches or relations orange to distinguish them.
\ifnotpaper
    Recommendations can also be inherited; for example, we generate
    \Cref{fig:perf-graph} based on the modifications we apply to
    \Cref{fig:recovery-graph-proposed,fig:scal-graph-proposed} and
    other changes from \Cref{perf-test-rec}.
\fi

\ifnotpaper
    \input{chapters/04a_flaw_analysis}
\else
    % Moved here to display nicely in paper
    \sntxFlawsTable{}
    \smntcFlawsTable{}
\fi
