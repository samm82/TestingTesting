\subsection{Flaw Analysis}
\label{flaw-analysis}

In addition to analyzing specific flaws, it is also useful to examine them at
a higher level. We automate subsets of this task where applicable
(\Cref{auto-flaw-analysis}) and augment the remaining manual portion with
automated tools (\Cref{aug-flaw-analysis}). This gives us an overview of:
\begin{itemize}
    \item how many flaws there are,
    \item how responsible each source tier (see \Cref{sources}) is for these flaws,
    \item how explicit (see \Cref{explicitness}) these flaws are,
    \item how these flaws present themselves (see \Cref{flawMnfsts}), and
    \item in which knowledge domains these flaws occur (see \Cref{flawDmns}).
\end{itemize}

\phantomsection{}\label{flaw-cred-compare}
To understand where flaws exist in the literature, we group them based on the
source tier(s) responsible for them. We then count each flaw \emph{once} per
source tier if it appears within it \emph{and/or} between it and a more
credible tier\footnote{If an inconsistency occurs between two source tiers
    and the more credible one is \emph{incorrect}, we instead count it as an
    inconsistency between it and the asserted truth from the less credible
    source, as described in \Cref{less-cred-assert}.} (see \Cref{cred,sources}).
This avoids counting the same flaw
more than once for a given source tier\thesisissueref{83}, which would give the
number of \emph{occurrences} of all flaws instead of the more useful number of
flaws \emph{themselves}. When taking a more detailed look at the \emph{sources}
of flaws (as opposed to just the responsible source \emph{tiers}), as we do in
\Cref{fig:flawBars}, we also count the following sources of flaws separately:
\begin{enumerate}
    \item those that appear once in (or consistently throughout) a document
          (i.e., are ``self-contained'')\thesisissueref{137,138},
    \item those between two parts of a single document
          (i.e., internal conflicts)\thesisissueref{137,138},
    \item those between documents with the same set of authors, which includes
          \begin{enumerate}
              \item the various combinations of ISO, the \acf{iec}, and IEEE
                    shown in \Cref{fig:ieeeSourceSets} and
              \item the different versions of the \acfp{swebok}, which have
                    different editors \citep{SWEBOK2024,SWEBOK2014} but are
                    written by the same organization: the IEEE Computer Society
                    (\citealp{AboutSWEBOK}; see \Cref{metas}), and
          \end{enumerate}
    \item those within a single source tier.
\end{enumerate}
As before, we do not double count these sources of flaws, meaning that the
maximum number of counted flaws possible within a \emph{single} source tier in
this more detailed view is four (one for each type). This only occurs if there
is an example of each flaw source that is \emph{not} ignored to avoid double
counting; for example, while a single flaw within a single document would
technically and trivially fulfill all four criteria, we would only count it
once.

\begin{figure}[bt!]
    \centering
    \begin{tikzpicture}
        \def\radius{3.6cm}
        \def\spread{1.5}
        \def\offset{\spread*1.6}

        \draw (-\spread, 0) circle (\radius);
        \draw ( \spread, 0) circle (\radius);
        \draw (0, -\offset) circle (\radius);

        \node[above] at (-\offset,        \radius) {ISO};
        \node[above] at ( \offset,        \radius) {IEC};
        \node[above] at (0, -\offset-1.85*\radius) {IEEE};

        % ALL
        \node[above] at (0, -\spread-0.5) {\parbox{3.7cm}{\centering
                \citealp{IEEE2022,IEEE2021,IEEE2019a,IEEE2019b,IEEE2017,
                    IEEE2016,IEEE2013,IEEE2010}}};
        % ISO/IEC
        \node[above] at (0, 0.325*\radius) {\parbox{2.8cm}{\centering
                \citealp{ISO_IEC2023a,ISO_IEC2023b,ISO_IEC2018,ISO_IEC2015,ISO_IEC2011}}};
        % ISO/IEEE
        \node[above] at ( \offset, -\offset) {---};
        % IEC/IEEE
        \node[above] at (-\offset, -\offset) {---};

        % ISO
        \node[above] at (-1.4*\offset, 0.25) {\parbox{2cm}{\centering
                \citealp{ISO2022,ISO2015}}};
        % IEC
        \node[above] at ( 1.4*\offset, 0.25) {---};
        % IEEE
        \node[above] at (0, -\spread-1.4*\radius) {\citealp{IEEE2012}};

    \end{tikzpicture}
    \caption{The sets of authors of established standards (as defined in
        \Cref{stds}).}\label{fig:ieeeSourceSets}
\end{figure}

% \phantomsection{}\label{flaw-analysis-example}
% As an example of this process, consider \flawref{level-phase-syns}, where an
% IEEE standard has an internal flaw, an inconsistency with two other IEEE
% standards, and an inconsistency with a textbook. This adds one to the following
% rows of \Cref{tab:flawMnfsts,tab:flawDmns} in the relevant column for a total
% of two counted flaws:

% \begin{itemize}
%     \item \textbf{\stds{}}: this flaw occurs:
%           \begin{enumerate}
%               \item within one standard and
%               \item between three standards (with the same set of authors).
%           \end{enumerate}
%           This increments the count by just one to avoid double counting and
%           would do so even if only one of the above conditions was true. A more
%           nuanced breakdown of flaws that identifies those within a
%           singular document and those between documents by the same author is
%           given in \Cref{fig:flawBars} and explained in more detail in
%           \Cref{aug-flaw-analysis}; this view counts three total flaws here.
%     \item \textbf{\texts{}}: this flaw occurs between a source in this tier and
%           a ``more credible'' one (the IEEE standards; see \Cref{cred}).
%           % \item \textbf{\papers{}}: this flaw occurs between a source in this tier
%           %       and a ``more credible'' one. Even though there are two sources in this
%           %       tier \emph{and} two ``more credible'' tier involved, this increments
%           %       the count by just one to avoid double counting.
% \end{itemize}

\subsubsection{Automated Flaw Analysis}\label{auto-flaw-analysis}

As outlined in \Cref{relevantSyns}, we automatically detect synonym relations
from \ourApproachGlossary{} that violate transitivity to generate our graphs.
These relations are significant because they indicate potential flaws. We
automatically detect and format these flaws to present them when discussing
synonym relation flaws in \Cref{syns}. % \Cref{multiSyns,infMultiSyns}
The next logical step is then to detect other classes of flaws.

\ExampleFlawGraphs{}

\phantomsection{}\label{selfParDef}
Parent-child relations that violate irreflexivity as outlined in
\Cref{par-chd-rels} (i.e., cases where a child is given as a parent of itself)
are also trivial to automate by looking for lines in the
generated \LaTeX{} files that start with \texttt{I~->~I}, where \texttt{I}
is the label used for a test approach node in these graphs. This process
results in output similar to \Cref{fig:selfExampleGraph}.% \Cref{selfPars}
\phantomsection{}\label{parSynDef} We use a similar
process to detect pairs of approaches with a synonym relation \emph{and} a
parent-child relation; these are flaws since synonym relations are symmetric
while parent-child relations are asymmetric as outlined in \Cref{syn-rels,%
    par-chd-rels}, respectively. To find these flaws, we build a dictionary of
each term's synonyms to evaluate which synonym relations are notable enough
to include in the graph, and then check these mappings to see if one appears
as a parent of the other. For example, if \texttt{J} and \texttt{K} are
synonyms, a generated \LaTeX{} file with a parent line starting with
\texttt{J~->~K} \emph{or} \texttt{K~->~J} would result in these approaches
being graphed as shown in \Cref{fig:parSynExampleGraph}. We present these two
classes of flaws when discussing parent-child relation flaws in \Cref{pars}.
% \Cref{tab:parSyns,infParSyns}

While just counting the total number of flaws (found automatically \emph{or}
manually) is trivial, tracking
the source(s) of these flaws is more useful, albeit more involved. Since
we consistently track the appropriate citations for each piece of information
we record (see \Cref{tab:exampleGlossary} for an example % tab:synExampleGlossary
of how we format these citations in our glossaries), we can use them to
identify the offending source tier(s). This comes with the added benefit that
we can format these citations to use with \LaTeX{}'s citation commands in this
\docType{}, including generating the comments used to analyze flaws as
described in \Cref{aug-flaw-analysis}.

\phantomsection{}\label{auto-flaw-analysis-explicitness}
Alongside this citation information, we include keywords so we can assess how
``explicit'' a piece of information is (see \Cref{explicitness}). This is
useful when counting flaws, since they can be both objective and subjective but
should not be double counted as both\thesisissueref{83,176}! When presenting
the numbers of flaws sorted by various criteria in
\Cref{tab:flawMnfsts,tab:flawDmns}, each flaw is counted only for its
most ``explicit'' manifestation (i.e., it will only increment a value in the
``(Sub)jective'' column if it is \emph{not} also ``(Obj)ective''),
similarly to how we generate graphs (see \Cref{graphExplicit}).

\subsubsection{Augmented Flaw Analysis}\label{aug-flaw-analysis}
While we can detect some subsets of flaws automatically by analyzing
\ourApproachGlossary, most are too complex and need to be tracked manually. We
record these more detailed flaws as \LaTeX{} enumeration items along with
comments that we can parse automatically, allowing us to analyze them more
broadly. We also add these comments to flaws we detect automatically before
generating the corresponding \LaTeX{} file to ensure these flaws also get
analyzed. These comments have the following format:
\begin{displayquote}
    \texttt{\% Flaw count (MNFST, DMN): \{A1\} \{A2\} \dots{} | \{B1\} % \{B2\}
        \dots{} | \{C1\} \dots}
\end{displayquote}
\texttt{MNFST} and \texttt{DMN} are placeholders for the ``keys'' given in
\Cref{tab:flawMnfstDefs,tab:flawDmnDefs}, respectively, that we use to track a
flaw's manifestation(s) and domain(s) (defined in \Cref{flaw-def}). We omit
these keys from constructed examples of these comments without associated flaws
throughout this chapter for brevity. Finally, \texttt{A1}, \texttt{A2}, % \texttt{B2},
\texttt{B1}, and \texttt{C1} are each placeholders for a source involved in
this example flaw; in general, there can be arbitrarily many. We represent each
source by its \BibTeX{} key, and wrap each one in curly braces (with the
exception of the \acs{istqb} glossary due to its use of custom commands via
\macro{citealias}) to mimic \LaTeX{}'s citation commands for ease of parsing.
We then separate each ``group'' of sources with a pipe symbol (\texttt{|}) so
we can compare each pair of groups; in general, a flaw can have any number of
groups of sources.

We make a distinction between ``self-contained'' flaws and ``internal'' flaws.
Self-contained flaws are those that manifest by comparing a document to an
assertion of ground truth. Sometimes, these do not require an explicit comparison;
for example, omissions (listed in \Cref{miss}) often fall into this category,
since the lack of information is contained within a single source and does not
need to be cross-checked against an assertion of ground truth. If only one group
of sources is present in a flaw's comment, such as the first line below, we
consider it to be a self-contained flaw. On the other hand, internal flaws
arise when a document disagrees with itself by containing two conflicting
pieces of information; this includes many contradictions and overlaps (listed
in \Cref{contra,over}, respectively). These can even occur on the same page,
such as when a source gives an acronym to two distinct terms
(see \flawref{cat-acro,hil-acro})! If a
source appears in multiple groups in a flaw's comment, we consider it to
be an internal flaw. The second line is a standard example of this, while the
third is more complex; in this case, source Y agrees with only one of the
conflicting sources of information in X.
\begin{displayquote}
    \texttt{\% Flaw count: \{X\}\\\% Flaw count: \{X\} | \{X\}\\
        \% Flaw count: \{X\} | \{X\} \{Y\}}
\end{displayquote}
We do not double count flaws that reappear when comparing between pairs of
groups; this means the following line adds an inconsistency between X and Z
\emph{and} between Y and Z \emph{without} double counting the former.
\begin{displayquote}
    \texttt{\% Flaw count: \{X\} | \{X\} \{Y\} | \{Z\}}
\end{displayquote}

We compare the authors and years of each source involved with a given flaw
to determine if it manifests within a single document and/or between documents
with the same set of authors. Then, we group these sources into their tiers
\seeSrcCode{82167b7}{scripts/flawCounter.py}{63}{80}.
% done by the function in \Cref{lst:getSrcCat}, since each source tier
% outlined in \Cref{sources} is comprised of a small number of authors (with the
% exception of papers and other documents; see \Cref{papers}).
We then distill these lists of sources down to sets of tiers and compare them
against each other to determine how many times a given flaw manifests between
source tiers. This determines which row(s) of \Cref{tab:flawMnfsts,tab:flawDmns}
and which bar(s) of \Cref{fig:flawBars} that the given flaw should count toward.
We describe this process in more detail in \Cref{aug-flaw-analysis}.

To give a more complete example, we track \flawref{level-phase-syns} with the
following comment line:\utd{}
\begin{displayquote}
    \texttt{\% Flaw count (OVER, SYNS): \{IEEE2017\} \{IEEE2013\} | \{IEEE2022\}
        \displayNL{} \{IEEE2017\} \{Perry2006\}}
\end{displayquote}%
% We parse this as the example given in \Cref{flaw-analysis-example}.
Since \texttt{IEEE2022}, \texttt{IEEE2017}, and \texttt{IEEE2013} are all
written by the same standards
organizations (\begin{NoHyper}\citeauthor{IEEE2022}\end{NoHyper}), we count
this as an inconsistency between documents with the same set of authors in
\Cref{fig:flawBars}, but only once to avoid double counting.

We can also specify the ``explicitness'' (see \Cref{explicitness}) of a flaw by inserting
the phrase ``implied by'' after the sources of explicit information and before
those of implicit information. This information is parsed following the same
rules described in \Cref{auto-flaw-analysis-explicitness} for automatically
detected flaws. Note that we only count subjective flaws if there is not an
equivalent objective flaw, as we do when generating graphs (\Cref{graphExplicit}).
\begin{displayquote}
    \texttt{\% Flaw count (CONTRA, DEFS): \{IEEE2021\} \{IEEE2017\} |
        \displayNL \{vanVliet2000\} implied by \{IEEE2021\}}
\end{displayquote}
For example, the above comment line\utd{} from \flawref{c-use-def} indicates
that the flaws given below are present. The third flaw only affects
\Cref{fig:flawBars} due to its more nuanced breakdown of the
sources of flaws. The rest increment their corresponding count in
\Cref{fig:flawBars,tab:flawMnfsts,tab:flawDmns} by only one:
\begin{itemize}
    \item an objective inconsistency between a textbook and a standard,
    \item a subjective flaw within a single document, and
    \item a subjective inconsistency between documents with the same set of
          authors (\begin{NoHyper}\citeauthor{IEEE2022}\end{NoHyper}).
\end{itemize}

\phantomsection{}\label{less-cred-assert}
Occasionally, we assert that a source from a less credible tier is more correct
than a source from a more credible tier\thesisissueref{184}.
For example, \tolTestFlaw*{} This flaw is supported
by additional papers found via a miniature literature review (described in
\Cref{undef-terms}) from a lower source tier than \citep{Firesmith2015}
(which is a terminology collection; see \Cref{sources}). However, this flaw
is really based in \citep{Firesmith2015} and not in these
additional papers, but this would be counted as a flaw in these papers if they
were included as detailed above. Therefore, we document these ``assertion''
sources separately to track them for traceability without incorrectly
counting flaws, such as the following for this specific example
(\flawref{assert-truth}):
\begin{displayquote}
    \texttt{\% Flaw count (WRONG, LABELS): \{Firesmith2015\}\\
        \% Assertion: \{LiuEtAl2023\} \{MorgunEtAl1999\} \{HolleyEtAl1996\}
        \displayNL \{HoweAndJohnson1995\}}
\end{displayquote}

\subsection[LaTeX Commands]{\LaTeX{} Commands}\label{macros}
To improve maintainability, traceability, and reproducibility, we define
helper commands (also called ``macros'') for content that is prone to change
or used in multiple places. For example, we use Python scripts to calculate
values based on our glossaries and save them to files to be assigned to
corresponding \LaTeX{} macros. We use these throughout our documents instead of
manually updating these constantly changing values, which is prone to error.
\Cref{tab:macrosCalc} lists these macros, along with their current values and
descriptions of what they represent. Our Python scripts convert numbers to
their textual equivalents when necessary to follow IEEE guidelines.

\input{assets/tables/macrosCalc}

\phantomsection{}\label{flawCounts}
Additionally, we count flaws based on their manifestation and domain, explicitness,
and source tier (defined in \Cref{flaw-def,explicitness,sources}, respectively).
For each source tier, we create two files that each include both levels of
explicitness: one for manifestations and one for domains. For example, flaws in
standards are saved to \texttt{build/stdFlawMnfstBrkdwn.tex} by manifestation%
% and \texttt{build/stdFlawDmnBrkdwn.tex} for domains
. We then assign these data to macros (such as \macro{stdFlawMnfstBrkdwn}) to
populate \Cref{tab:flawMnfsts,tab:flawDmns}. For example, we access the number
of objective and subjective mistakes in standards by using
\macro[1]{stdFlawMnfstBrkdwn} and \macro[2]{stdFlawMnfstBrkdwn}, respectively.
We follow a similar process for tracking the total numbers of flaws; this
includes \macro[13]{totalFlawMnfstBrkdwn} and \macro[13]{totalFlawDmnBrkdwn}
which are identical and track the total number of identified flaws.

\phantomsection{}\label{text-macros}
Just as with calculated values, it is important that repeated text is updated
consistently, which we accomplish by defining more macros. Some of these are
generated by Python scripts in a similar fashion to calculated values, such as
those for flaw manifestations and domains in \Cref{tab:macrosSections} and the
lists of sources in each source tier. The latter are built by extracting all
sources cited in our three glossaries, categorizing, sorting, and formatting
them (including handling edge cases), and saving them to a file. These are then
assigned to \macro{stdSources}, \macro{metaSources}, \macro{textSources}, and
\macro{paperSources} and include:
\begin{enumerate}
    \item the source tier's name,
    \item the list of sources in the tier, and
    \item the number of sources in the tier.
\end{enumerate}
These are accessed by passing in the corresponding number in the above
enumeration (e.g., \macro[2]{paperSources}). We use the first value for the
subheadings in \Cref{sources}, the first two for \Cref{app-src-tiers} and the
third to build \Cref{fig:sourceSummary} and calculate \macro{srcCount}
(see \Cref{tab:macrosCalc}).
% We also define macros for well-defined sections in \Cref{tab:macrosSections}.

However, we create most of these macros for reused text manually when we first
notice the reuse, including the source tier macros in \Cref{tab:macrosSections}.
Some of these macros account for context-specific formatting depending on how
they are used, such as capitalization. These tend to be less well-defined,
since they arise naturally from the writing process, so we omit these details
from the manually created text macros in \Cref{tab:macrosText}, which are
grouped based on the type of information they contain.

\begin{landscape}
    \input{assets/tables/macrosSections}
\end{landscape}
\input{assets/tables/macrosText}
